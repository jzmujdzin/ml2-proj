{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d935d4c145b69da8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## German Credit Risk Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ddde6fa090b655",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Problem Description\n",
    "The dataset comes from UC Irvine Machine Learning Repository. According to the source, \"this dataset classifies people described by a set of attributes as good or bad credit risks.\" The dataset contains 2000 observations with 32 features - some information has been tweaked by the course coordinator. The features are a mix of numeric and categorical values. The target variable is a binary variable indicating whether the person is a good or bad credit risk, according to the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5149f5234efce33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:42:13.747853Z",
     "start_time": "2023-12-09T14:42:13.637991Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>class</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>duration</th>\n",
       "      <th>employment</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>feat01</th>\n",
       "      <th>...</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>purpose</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>savings_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>2319</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>21</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>2</td>\n",
       "      <td>0.239898</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>2</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>1163</td>\n",
       "      <td>'delayed previously'</td>\n",
       "      <td>15</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521139</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>'life insurance'</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>2</td>\n",
       "      <td>'&gt;=1000'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>1502</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>10</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286838</td>\n",
       "      <td>...</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>'new car'</td>\n",
       "      <td>4</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>4436</td>\n",
       "      <td>'delayed previously'</td>\n",
       "      <td>36</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430937</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>4</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>10155</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>60</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.439643</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>4</td>\n",
       "      <td>'100&lt;=X&lt;500'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>30</td>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>good</td>\n",
       "      <td>1743</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>6</td>\n",
       "      <td>'&lt;1'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353228</td>\n",
       "      <td>...</td>\n",
       "      <td>'high qualif/self emp/mgmt'</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>'male mar/wid'</td>\n",
       "      <td>car</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>3</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>24</td>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>bad</td>\n",
       "      <td>2994</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>18</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644627</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>2</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>26</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>1255</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>12</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597782</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>'male mar/wid'</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>business</td>\n",
       "      <td>2</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>39</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>1637</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>12</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462609</td>\n",
       "      <td>...</td>\n",
       "      <td>'high qualif/self emp/mgmt'</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>car</td>\n",
       "      <td>'new car'</td>\n",
       "      <td>4</td>\n",
       "      <td>'&lt;100'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>55</td>\n",
       "      <td>'no checking'</td>\n",
       "      <td>good</td>\n",
       "      <td>1439</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>12</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506794</td>\n",
       "      <td>...</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>'life insurance'</td>\n",
       "      <td>'used car'</td>\n",
       "      <td>2</td>\n",
       "      <td>'&gt;=1000'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  age checking_status class  credit_amount  \\\n",
       "0        1   50   'no checking'  good           2319   \n",
       "1        2   30   'no checking'  good           1163   \n",
       "2        3   32   'no checking'  good           1502   \n",
       "3        4   34   'no checking'  good           4436   \n",
       "4        5   21   'no checking'  good          10155   \n",
       "...    ...  ...             ...   ...            ...   \n",
       "1995  1996   30      '0<=X<200'  good           1743   \n",
       "1996  1997   24            '<0'   bad           2994   \n",
       "1997  1998   26   'no checking'  good           1255   \n",
       "1998  1999   39   'no checking'  good           1637   \n",
       "1999  2000   55   'no checking'  good           1439   \n",
       "\n",
       "                        credit_history  duration employment  existing_credits  \\\n",
       "0                      'existing paid'        21      '>=7'                 2   \n",
       "1                 'delayed previously'        15   '4<=X<7'                 2   \n",
       "2     'critical/other existing credit'        10      '>=7'                 2   \n",
       "3                 'delayed previously'        36   '1<=X<4'                 2   \n",
       "4                      'existing paid'        60   '4<=X<7'                 1   \n",
       "...                                ...       ...        ...               ...   \n",
       "1995                   'existing paid'         6       '<1'                 1   \n",
       "1996                   'existing paid'        18   '1<=X<4'                 1   \n",
       "1997                   'existing paid'        12   '1<=X<4'                 1   \n",
       "1998                   'existing paid'        12      '>=7'                 1   \n",
       "1999                   'existing paid'        12   '4<=X<7'                 1   \n",
       "\n",
       "        feat01  ...                          job  num_dependents  \\\n",
       "0     0.239898  ...                      skilled               1   \n",
       "1     0.521139  ...                      skilled               1   \n",
       "2     0.286838  ...         'unskilled resident'               2   \n",
       "3     0.430937  ...                      skilled               1   \n",
       "4     0.439643  ...                      skilled               1   \n",
       "...        ...  ...                          ...             ...   \n",
       "1995  0.353228  ...  'high qualif/self emp/mgmt'               1   \n",
       "1996  0.644627  ...                      skilled               1   \n",
       "1997  0.597782  ...                      skilled               1   \n",
       "1998  0.462609  ...  'high qualif/self emp/mgmt'               1   \n",
       "1999  0.506794  ...                      skilled               1   \n",
       "\n",
       "      other_parties  other_payment_plans  own_telephone       personal_status  \\\n",
       "0              none                 none           none         'male single'   \n",
       "1              none                 none           none  'female div/dep/mar'   \n",
       "2              none                 none           none         'male single'   \n",
       "3              none                 none           none  'female div/dep/mar'   \n",
       "4              none                 none            yes  'female div/dep/mar'   \n",
       "...             ...                  ...            ...                   ...   \n",
       "1995           none                 none            yes        'male mar/wid'   \n",
       "1996           none                 none           none  'female div/dep/mar'   \n",
       "1997           none                 none            yes        'male mar/wid'   \n",
       "1998           none                 none            yes         'male single'   \n",
       "1999           none                 none           none         'male single'   \n",
       "\n",
       "      property_magnitude              purpose  residence_since savings_status  \n",
       "0          'real estate'  furniture/equipment                2         '<100'  \n",
       "1       'life insurance'  furniture/equipment                2       '>=1000'  \n",
       "2          'real estate'            'new car'                4         '<100'  \n",
       "3          'real estate'             radio/tv                4         '<100'  \n",
       "4          'real estate'             radio/tv                4   '100<=X<500'  \n",
       "...                  ...                  ...              ...            ...  \n",
       "1995                 car             radio/tv                3         '<100'  \n",
       "1996       'real estate'             radio/tv                2         '<100'  \n",
       "1997       'real estate'             business                2         '<100'  \n",
       "1998                 car            'new car'                4         '<100'  \n",
       "1999    'life insurance'           'used car'                2       '>=1000'  \n",
       "\n",
       "[2000 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/c2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62810a8bf0ecdff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:43:11.852225Z",
     "start_time": "2023-12-09T14:43:11.838065Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      2000 non-null   int64  \n",
      " 1   age                     2000 non-null   int64  \n",
      " 2   checking_status         2000 non-null   object \n",
      " 3   class                   2000 non-null   object \n",
      " 4   credit_amount           2000 non-null   int64  \n",
      " 5   credit_history          2000 non-null   object \n",
      " 6   duration                2000 non-null   int64  \n",
      " 7   employment              2000 non-null   object \n",
      " 8   existing_credits        2000 non-null   int64  \n",
      " 9   feat01                  2000 non-null   float64\n",
      " 10  feat02                  2000 non-null   float64\n",
      " 11  feat03                  2000 non-null   float64\n",
      " 12  feat04                  2000 non-null   float64\n",
      " 13  feat05                  2000 non-null   float64\n",
      " 14  feat06                  2000 non-null   float64\n",
      " 15  feat07                  2000 non-null   float64\n",
      " 16  feat08                  2000 non-null   float64\n",
      " 17  feat09                  2000 non-null   float64\n",
      " 18  feat10                  2000 non-null   float64\n",
      " 19  foreign_worker          2000 non-null   object \n",
      " 20  housing                 2000 non-null   object \n",
      " 21  installment_commitment  2000 non-null   int64  \n",
      " 22  job                     2000 non-null   object \n",
      " 23  num_dependents          2000 non-null   int64  \n",
      " 24  other_parties           2000 non-null   object \n",
      " 25  other_payment_plans     2000 non-null   object \n",
      " 26  own_telephone           2000 non-null   object \n",
      " 27  personal_status         2000 non-null   object \n",
      " 28  property_magnitude      2000 non-null   object \n",
      " 29  purpose                 2000 non-null   object \n",
      " 30  residence_since         2000 non-null   int64  \n",
      " 31  savings_status          2000 non-null   object \n",
      "dtypes: float64(10), int64(8), object(14)\n",
      "memory usage: 500.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99873d489a03df7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Description\n",
    "The dataset contains 2000 observations with 31 features - \"id\" column was left out. Feature information:\n",
    "- 17 variables are natively of type numeric (age, credit_amount, duration, existing_credits, feats 1 through 10, installment_commitement. num_dependents, residence_since)\n",
    "- 14 variables are natively of type string (checking_status, class, credit_history, employment, foreign_worker, housing, job, other_parties, other_payment_plans, own_telephone, personal_status, property_magnitude, purpose, savings_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a790d3daf0312d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:54:03.396244Z",
     "start_time": "2023-12-09T14:53:12.476077Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0779624acde45a7b88848ca87b46ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24a12bf84a240188b502bd18988de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f61481ad81a44f89c9f7add2025f605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b93b9539d4e46e7a8b9e63bcc2c1772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "profile.to_file(\"classification_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578c6306c2f0e05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Variable Insights\n",
    "- age: 19-75, mean 35.5, median 33, std 11.2 - most of the people are in their 30s, with possibly a lot of time to still pay the credit back\n",
    "- checking_status: 4 categories, most people have no checking account, followed by poeple having less than 0 (\"<0\" category) DM in their account, followed by 0<=...<200 DM, followed by >=200 DM - this variable can be remapped to a numeric variable - we propose the following mapping: \"no checking account\" = -1, \"<0 DM\" = 0, \"0<=...<200 DM\" = 200, \">=200 DM\" = 400\n",
    "- class: the target variable - 2 categories, 69,1% of the people are classified as \"good\" credit risk, 30% as \"bad\" credit risk - the dataset is imbalanced - we will need to take this into account when evaluating the model. We will remap the target variable to 0 and 1, where 0 = \"good\" credit risk and 1 = \"bad\" credit risk.\n",
    "- credit_amount: 250-18422, mean 3238 - the credit amounts vary a lot, with most of the people having a credit amount of less than 5000 DM. The variable's distribution is right-skewed, with a possibility to use log transformation for this variable.\n",
    "- credit_history: 5 categories, most people have existing paid credits, followed by people having critical/other existing credits, followed by people having credits delayed previously, followed by people having \"all paid\" credits, finally with people having \"no credits/all paid\" status. We believe that this category can be crucial in further evaluating the credit risk, as people who have had problems with paying their credits in the past are more likely to have problems in the future.\n",
    "- duration: 4-72, mean 20.7 - the duration of the credit varies a lot, with most of the people having a credit duration of less than 30 months. The variable's distribution is right-skewed. We believe that this variable can be crucial in further evaluating the credit risk, as people who have a longer credit duration are more likely to have problems with paying the credit back.\n",
    "- employment: 5 categories, most people are employed for between 1 and 4 years, followed by people employed for longer than 7 years, followed by people being employed between 4 and 7 years, followed by people employed for less than a year, finally we have category of people that are unemployed. We propose a remapping of the variable, where \"unemployed\" = -1, \"<1 year\" = 1, \"1<=...<4 years\" = 4, \"4<=...<7 years\" = 7, \">=7 years\" = 10.\n",
    "- existing_credits: 1-4, mean 1.4 - most of the people have 1 existing credit, followed by people having 2 existing credits, followed by people having 3 existing credits, finally followed by people having 4 existing credits. Most of the people have 1 credit (1253) or 2 credits (672 people).\n",
    "- feat01: numeric in within range of 0 and 1, with mean = 0.46, std = 0.152. Looks like normal distribution.\n",
    "- feat02: numeric in within range of 0 and 1, with mean = 0.57, std = 0.116. Less variance than feat01, but still looks somewhat like normal distribution.\n",
    "- feat03: numeric in within range of 0.09 and 1.84, with mean = 1.03, std = 0.32. Higher variance than feat01.\n",
    "- feat04: numeric in within range of 0.12 and 1.87, with mean = 0.98, std = 0.32. Very similiar distrubution to feat03.\n",
    "- feat05: numeric in within range of 0.08 and 1.87, with mean = 0.98, std = 0.33. Very similiar distrubution to feat03 and feat04.\n",
    "- feat06: numeric in within range of 0.16 and 1.84, with mean = 1.01, std = 0.32. Very similiar distrubution to feat03, feat04 and feat05.\n",
    "- feat07: numeric in within range of 0.11 and 1.80, with mean = 0.98, std = 0.32. Very similiar distrubution to feat03, feat04, feat05 and feat06.\n",
    "- feat08: numeric in within range of 0.10 and 1.87, with mean = 1.01, std = 0.32. Very similiar distrubution to feat03, feat04, feat05, feat06 and feat07.\n",
    "- feat09: numeric in within range of 0.14 and 1.95, with mean = 0.98, std = 0.32. Very similiar distrubution to feat03, feat04, feat05, feat06, feat07 and feat08.\n",
    "- feat10: numeric in within range of 0 and 1, with mean = 0.5, std = 0.14. Very similiar distrubution to feat01.\n",
    "- foreign_worker: 2 categories, most people are foreign workers, followed by people being native workers.\n",
    "- housing: 3 categories, most people have their own housing (1444), followed by people living in rented housing, followed by people living for free.\n",
    "- installment_commitment: categories 1-4 - most of the people have installment commitment of 4, followed by people having installment commitment of 2 - this is installment rate in % of disposable income. Almost half of the people had installment commitment of 4 (978), followed by people having installment commitment of 2 (455).\n",
    "- job: 4 categories, most people have skilled job (1258), followed by people being unskilled residents, followed by people being highly qualified/self-employed, with few people beying unemployed/unskilled non-resident.\n",
    "- num_dependents: 1-2 - most of the people have 1 dependent (1694), followed by people having 2 dependents.\n",
    "- other_parties: 3 categories, most people have none (1818), followed by people having guarantor (104) and co applicant. This will probably be a very important variable in further evaluating the credit risk.\n",
    "- other_payment_plans: 3 categories, most people have none (1634), followed by people having bank and stores payment plans.\n",
    "- own_telephone: 2 categories, most people dont have their own telephone (1174), followed by people having their own telephone.\n",
    "- personal_status: 4 categories, most of the people (1065) are male singles, 649 of them are females divorced/dep or married, about 25% of them are married/widowed males and 105 of the people are males after divorce or separation\n",
    "- property_magnitude: 4 categories, most people have a car (668), followed by people having real estate, followed by people having life insurance, followed by people having no property.\n",
    "- purpose: 10 categories, most people take credit for radio/tv (563), followed by people taking credit for new car, furniture/equipment, business, used car, education, repairs, domestic appliances, other and retraining. This feature should be highly correlated with the amount that a person want to take credit for.\n",
    "- residence_since: 1-4 - most of the people have been living at their current residence for 4 years, followed by people living there for 2 years, followed by people living there for 3 years, followed by people living there for 1 year.\n",
    "- savings_status: 5 categories, most people have less than 100 DM in their savings account, followed by people having no known savings, followed by people having between 100 and 500 DM, followed by people having between 500 and 1000 DM, followed by people having more than 1000 DM. This variable can be remapped to a numeric variable - we propose the following mapping: \"no known savings\" = -1, \"<100 DM\" = 100, \"100<=...<500 DM\" = 500, \"500<=...<1000 DM\" = 1000, \">=1000 DM\" = 2000. This can impact the credit risk, as people with more savings are more likely to pay the credit back.\n",
    "\n",
    "Correlations:\n",
    "- credit amount and duration are highly correlated - this is expected, as the longer the credit duration, the higher the credit amount\n",
    "- feats 1 through 10 are uncorrelated with each other\n",
    "- housing and property magnitude are highly correlated - this is expected, as people with owning housing means higher property magnitude\n",
    "\n",
    "Missing values:\n",
    "- no missing values in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e852f929b179e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Variable transformations\n",
    "- checking_status: remap to a numeric variable - we propose the following mapping: \"no checking account\" = -1, \"<0 DM\" = 0, \"0<=...<200 DM\" = 200, \">=200 DM\" = 400\n",
    "- class: remap to 0 and 1, where 0 = \"good\" credit risk and 1 = \"bad\" credit risk\n",
    "- employment: remap to a numeric variable, where \"unemployed\" = -1, \"<1 year\" = 1, \"1<=...<4 years\" = 4, \"4<=...<7 years\" = 7, \">=7 years\" = 10\n",
    "- credit_amount: log transformation\n",
    "- savings_status: remap to a numeric variable - \"no known savings\" = -1, \"<100 DM\" = 100, \"100<=...<500 DM\" = 500, \"500<=...<1000 DM\" = 1000, \">=1000 DM\" = 2000\n",
    "\n",
    "Importantly - each of these transformations can be done on the whole dataset since there is no risk of data leakage with such transformations. Further transformations will be done (fitted) on the training set and then applied to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cc66aa294ea381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T15:42:31.216186Z",
     "start_time": "2023-12-09T15:42:30.800802Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['checking_status'] = df['checking_status'].map({\"'<0'\": 0, \"'0<=X<200'\": 200, \"'>=200'\": 400, \"'no checking'\": -1})\n",
    "\n",
    "df['employment'] = df['employment'].map({\"unemployed\": -1, \"'<1'\": 1, \"'1<=X<4'\": 4, \"'4<=X<7'\": 7, \"'>=7'\": 10})\n",
    "\n",
    "df['savings_status'] = df['savings_status'].map({\"'<100'\": 100, \"'100<=X<500'\": 500, \"'500<=X<1000'\": 1000, \"'>=1000'\": 2000, \"'no known savings'\": -1})\n",
    "\n",
    "df['class'] = df['class'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "df['credit_amount'] = df['credit_amount'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1db71cb3bc41c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T17:17:51.780421Z",
     "start_time": "2023-12-09T17:17:51.643115Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, x_out_of_sample, y, y_out_of_sample = train_test_split(df.drop(columns=['class', 'id']), df['class'], test_size=0.2, random_state=42, stratify=df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56e52ddba98e65",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Variable selection\n",
    "For this purpose, we will analyse the variables using the following methods:\n",
    "- Mutual information\n",
    "- Random Forest (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d6ddbcefc5107aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T16:03:37.151220Z",
     "start_time": "2023-12-09T16:03:36.714841Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checking       0.067681\n",
       "feat02         0.048123\n",
       "feat10         0.038384\n",
       "feat03         0.031934\n",
       "employment     0.026423\n",
       "num            0.023385\n",
       "duration       0.021285\n",
       "savings        0.020281\n",
       "age            0.017086\n",
       "foreign        0.015072\n",
       "feat01         0.014585\n",
       "installment    0.009563\n",
       "credit         0.008014\n",
       "purpose        0.006736\n",
       "personal       0.005348\n",
       "feat09         0.005086\n",
       "own            0.004734\n",
       "feat07         0.003551\n",
       "housing        0.003483\n",
       "existing       0.001743\n",
       "feat05         0.000000\n",
       "job            0.000000\n",
       "feat08         0.000000\n",
       "other          0.000000\n",
       "property       0.000000\n",
       "feat06         0.000000\n",
       "residence      0.000000\n",
       "feat04         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "X_train_numeric = pd.get_dummies(x, drop_first=True)\n",
    "mi = mutual_info_classif(X_train_numeric, y)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train_numeric.columns\n",
    "mi.groupby(lambda x: x.split('_')[0]).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4be6a22a83a84c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T16:20:56.032688Z",
     "start_time": "2023-12-09T16:20:54.825602Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAI/CAYAAABnFyD4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABN2UlEQVR4nO3dfZhfVX3v/ffHhAYJEGqNXmMQR2ioPEQCDLQqWvFZ01v0gAVBG9TT3IhItbU98XjsoVrbafEWpIo02hYfsKj4FM05QBURFBAmEBKeolSmBwIVrcc0gCCE7/3HbweHcSaZyUzmt2fyfl3XXLP32mut/d1z9SeTT9fak6pCkiRJkiRJaqsndLsASZIkSZIkaWsMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktZoBliRJkiRJklrNAEuSJEmSJEmtNrvbBUxHT37yk6u3t7fbZUiSJEmSJM0Yq1ev/klVzR/pmgHWdujt7WVgYKDbZUiSJEmSJM0YSf5ttGtuIZQkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1Gq+A2s7rNuwkd7lq6b8voP9S6b8npIkSZIkSd3WuhVYSU5PcmuSCyY4z6uTLJ+suiRJkiRJktQdbVyBdSrwyqq6Y1sdk8yuqkdGulZVK4GVk12cJEmSJEmSplarVmAlOQ/YF1iZ5E+SfCXJ2iTXJHl20+eMJCuSXAp8Ksn8JF9Mcl3z9bym38lJPtIc79fMcV2S9yW5r2l/YZLLk1yU5LYkFyRJlx5fkiRJkiRJI2hVgFVVpwB3A0cDvcANVfVs4L8DnxrS9XDgmKo6EfgwcFZVHQEcC3xihKk/DHy46XP3sGuHAu8ADqQTnj1vsp5HkiRJkiRJE9fGLYRbHEUnkKKqLkvyG0nmNddWVtXPm+OXAAcOWTi1Z5I9hs31HOA1zfFngQ8OuXZtVd0FkGQNneDsO8OLSbIMWAYwa8/52/1QkiRJkiRJGp82B1gjbeWr5vv9Q9qeADxnSKDVGTz2nYAPDTnezCg/k6paAawAmNOzsEbqI0mSJEmSpMnXqi2Ew1wBnASdd1UBP6mq/xyh36XAaVtOkiweoc81NKu5gBMms0hJkiRJkiTtWG0OsM4A+pKsBfqBpaP0O31LvyS3AKeM0OcdwB8nuRboATZOfrmSJEmSJEnaEVI183fDJdkN+HlVVZITgNdX1THbO9+cnoXVs/TsSatvrAb7l0z5PSVJkiRJkqZCktVV1TfStTa/A2syHQ58JJ0XY/0MePNEJlu0YB4DhkmSJEmSJElTYqcIsKrqSuCQbtchSZIkSZKk8WvzO7AkSZIkSZIkAyxJkiRJkiS1mwGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdVmd7uA6Wjdho30Ll/V7TImzWD/km6XIEmSJEmSNKqdYgVWkqu2cu2FSb4+lfVIkiRJkiRp7HaKAKuqntvtGiRJkiRJkrR9dooAK8l96TgzyU1J1iU5fkiXPZN8OcktSc5LslP8XCRJkiRJkqaDnekdWP8FWAwcAjwZuC7JFc21I4EDgX8DLm76XtSFGiVJkiRJkjTMzrTS6Cjgn6tqc1X9CPg2cERz7dqq+mFVbQb+uen7OEmWJRlIMrD5gY1TV7UkSZIkSdJObmcKsLKVa7WNc6pqRVX1VVXfrN3mTW5lkiRJkiRJGtXOFGBdARyfZFaS+cALgGuba0cmeWbz7qvjge90q0hJkiRJkiQ93s4SYBXwZWAtcCNwGfBnVfXvzfWrgX7gJuCOpq8kSZIkSZJaYMa/xD3JbwA/raoC/rT5ekxVXQ5cPvWVSZIkSZIkaSxmdICV5Gl0wqkPTua8ixbMY6B/yWROKUmSJEmSpFHM6ACrqu4G9u92HZIkSZIkSdp+O8s7sCRJkiRJkjRNGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS1mgGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWm93tAqajdRs20rt8VbfL2CEG+5d0uwRJkiRJkqTHcQWWJEmSJEmSWs0AS5IkSZIkSa027QOsJL1Jbk3y8SQ3J7k0yROTXJ6kr+nz5CSDzfHJSb6S5GtJ7khyWpI/TnJDkmuSPKmrDyRJkiRJkqTHmfYBVmMh8NGqOgj4GXDsNvofDJwIHAl8AHigqg4Frgb+YAfWKUmSJEmSpHGaKQHWHVW1pjleDfRuo/+3qmpTVf0Y2Ah8rWlfN9rYJMuSDCQZ2PzAxolXLEmSJEmSpDGZKQHWQ0OON9P564qP8Mvn23Ur/R8dcv4oo/xlxqpaUVV9VdU3a7d5E69YkiRJkiRJYzJTAqyRDAKHN8fHdbEOSZIkSZIkTcBMDrA+CLw1yVXAk7tdjCRJkiRJkrZPqqrbNUw7c3oWVs/Ss7tdxg4x2L+k2yVIkiRJkqSdUJLVVdU30rUR3/ekrVu0YB4DBj2SJEmSJElTYiZvIZQkSZIkSdIMYIAlSZIkSZKkVjPAkiRJkiRJUqsZYEmSJEmSJKnVDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLWaAZYkSZIkSZJabXa3C5iO1m3YSO/yVd0uY4cZ7F/S7RIkSZIkSZIe4wosSZIkSZIktdq0DLCSuHJMkiRJkiRpJ9G1ACtJb5LbknwyydokFyXZLclgkic3ffqSXN4cn5FkRZJLgU8lOTnJV5NcnGR9kv85ZO4/TnJT8/WOpm1uklVJbmzaj2/aD0/y7SSrk1ySpGfKfxiSJEmSJEkaVbdXMv0W8Jaq+m6SfwRO3Ub/w4GjqurnSU4GjgQOBh4ArkuyCijgTcBvAwG+l+TbwL7A3VW1BCDJvCS7AH8HHFNVP25CrQ8Ab57sB5UkSZIkSdL26XaAdWdVfbc5/gxw+jb6r6yqnw85/5eq+g+AJF8CjqITYH25qu4f0v584GLgg0n+Bvh6VV2Z5GA6Adi/JAGYBdwz0o2TLAOWAczac/64H1SSJEmSJEnbp9sBVo1w/gi/3Nq467Dr949hfEa8UdX3kxwOvAr462Yr4peBm6vqOdsstGoFsAJgTs/C4feVJEmSJEnSDtLtl7jvk2RLePR64DvAIJ2tggDHbmP8S5M8KckTgdcA3wWuAF7TvE9rLvBa4MokTwMeqKrPAB8EDgPWA/O31JBklyQHTdrTSZIkSZIkacK6vQLrVmBpkr8HfgB8DLgW+Ick/x343jbGfwf4NPCbwGeragAgyfnNPACfqKobkrwcODPJo8DDwFur6hdJjgPOSTKPzs/jbODmSXxGSZIkSZIkTUC3A6xHq+qUYW1XAvsP71hVZ4ww/t6qOm2Evh8CPjSs7RLgkhH6rgFeMPaSJUmSJEmSNJW6HWBNS4sWzGOgf0m3y5AkSZIkSdopdC3AqqpBOn8BcHvHnw+cP0nlSJIkSZIkqaW6/RJ3SZIkSZIkaasMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktZoBliRJkiRJklrNAEuSJEmSJEmtZoAlSZIkSZKkVjPAkiRJkiRJUqvN7nYB09G6DRvpXb6q22W0zmD/km6XIEmSJEmSZqAZsQIryV5JTh1y/sIkX+9mTZIkSZIkSZocMyLAAvYCTt1Wp7FK4so0SZIkSZKklpiWAVaSP05yU/P1DqAf2C/JmiRnNt12T3JRktuSXJAkzdjDk3w7yeoklyTpadovT/JXSb4N/FFXHkySJEmSJEm/YtqtNEpyOPAm4LeBAN8D3gAcXFWLmz4vBA4FDgLuBr4LPC/J94C/A46pqh8nOR74APDmZvq9qup3p+xhJEmSJEmStE3TLsACjgK+XFX3AyT5EvD8EfpdW1V3NX3WAL3Az4CDgX9pFmTNAu4ZMuZzo900yTJgGcCsPedP8BEkSZIkSZI0VtMxwMoY+z005HgznWcNcHNVPWeUMfePNllVrQBWAMzpWVhjrEGSJEmSJEkTNB3fgXUF8JokuyWZC7yWzhbBPcYwdj0wP8lzAJLskuSgHVeqJEmSJEmSJmrarcCqquuTnA9c2zR9oqpWJ/lukpuA/w2sGmXsL5IcB5yTZB6d5z8buHnHVy5JkiRJkqTtkSp3w41XX19fDQwMdLsMSZIkSZKkGSPJ6qrqG+nadNxCKEmSJEmSpJ2IAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS12uxuFzAdrduwkd7lq7pdxrQ02L+k2yVIkiRJkqRpxhVYwyS5PElft+uQJEmSJElSx7QKsJK4YkySJEmSJGknM+UBVpLeJLcl+WSStUkuSrJbksOTfDvJ6iSXJOlp+l+e5K+SfBv4oySvS3JTkhuTXNH02TXJPyVZl+SGJEc37Scn+VKSi5P8IMnfDqnjY0kGktyc5C+m+ucgSZIkSZKksenWiqbfAt5SVd9N8o/A24DXAsdU1Y+THA98AHhz03+vqvpdgCTrgJdX1YYkezXX3wZQVYuSPAu4NMn+zbXFwKHAQ8D6JH9XVXcC76mqnyaZBXwzybOrau2OfnBJkiRJkiSNT7e2EN5ZVd9tjj8DvBw4GPiXJGuA/wHsPaT/54Ycfxc4P8kfArOatqOATwNU1W3AvwFbAqxvVtXGqnoQuAV4RtP++0muB24ADgIO3FrBSZY1K7YGNj+wcbzPK0mSJEmSpO3UrRVYNex8E3BzVT1nlP73Pzaw6pQkvw0sAdYkWQxkK/d6aMjxZmB2kmcC7wKOqKr/m+R8YNetFly1AlgBMKdn4fD6JUmSJEmStIN0awXWPkm2hFWvB64B5m9pS7JLkoNGGphkv6r6XlX9OfAT4OnAFcBJzfX9gX2A9Vu5/550QrGNSZ4KvHISnkmSJEmSJEk7QLdWYN0KLE3y98APgL8DLgHOSTKvqets4OYRxp6ZZCGdVVffBG4EbgPOa96P9QhwclU9lIy8MKuqbkxyQzP/D+lsS5QkSZIkSVILpWpqd8Ml6QW+XlUHT+mNJ9GcnoXVs/TsbpcxLQ32L+l2CZIkSZIkqYWSrK6qvpGudWsF1rS2aME8BgxiJEmSJEmSpsSUB1hVNUjnLw5KkiRJkiRJ29Stl7hLkiRJkiRJY2KAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS1mgGWJEmSJEmSWm12twuYjtZt2Ejv8lXdLmPGGexf0u0SJEmSJElSC7kCS5IkSZIkSa02owKsJH+c5Kbm6x1J/izJ6c21s5Jc1hy/OMlnmuP7knwgyY1Jrkny1G4+gyRJkiRJkh5vxgRYSQ4H3gT8NvA7wB8CVwLPb7r0Absn2QU4qrkGMBe4pqoOAa5oxkmSJEmSJKklZkyARSeU+nJV3V9V9wFfAo4EDk+yB/AQcDWdIOv5/DLA+gXw9eZ4NdA70uRJliUZSDKw+YGNO+4pJEmSJEmS9DgzKcDKCG0FDNJZmXUVndDqaGA/4Namz8NVVc3xZkZ5sX1Vraiqvqrqm7XbvMmsW5IkSZIkSVsxkwKsK4DXJNktyVzgtXQCqyuAdzXfrwROAdYMCa0kSZIkSZLUYiOuNpqOqur6JOcD1zZNn6iqG5I8CXgPcHVV3Z/kQX65fVCSJEmSJEktN2MCLICq+hDwoWFt3wR2GXK+/7Druw85vgi4aAeXKUmSJEmSpHGYUQHWVFm0YB4D/Uu6XYYkSZIkSdJOYSa9A0uSJEmSJEkzkAGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktdrsbhcwHa3bsJHe5au6XcaMNNi/pNslSJIkSZKkltnpVmAleWGS53a7DkmSJEmSJI1NKwOsJLN20LyzgRcCBliSJEmSJEnTxJQHWEl6k9yW5JNJ1ia5KMluSQaT/HmS7wCvS/L6JOuS3JTkb4aMvy/J/5fk+iTfTDK/ad8vycVJVie5Msmzmvbzk3woybeAzwGnAO9MsibJ85PckWSXpu+eTR27TPXPRZIkSZIkSSPr1gqs3wJWVNWzgf8ETm3aH6yqo4ArgL8BXgQsBo5I8pqmz1zg+qo6DPg28D+b9hXA26vqcOBdwLlD7rc/8JKqOhY4DzirqhZX1ZXA5cCWFy+dAHyxqh6e3MeVJEmSJEnS9upWgHVnVX23Of4McFRz/Lnm+xHA5VX146p6BLgAeEFz7dEh/T4DHJVkdzrbAr+QZA3w90DPkPt9oao2j1LLJ4A3NcdvAv5ppE5JliUZSDKw+YGNY3xMSZIkSZIkTVS3/gphjXJ+f/M945zrCcDPqmrxKH3uH6Wdqvpus63xd4FZVXXTKP1W0FnlxZyehcPrlyRJkiRJ0g7SrRVY+yR5TnP8euA7w65/D/jdJE9uXuj+ejrbBaFT83HN8YnAd6rqP4E7krwOIB2HjHLvTcAew9o+Bfwzo6y+kiRJkiRJUvd0K8C6FViaZC3wJOBjQy9W1T3Au4FvATfSeefVV5vL9wMHJVlN5x1Z72vaTwLekuRG4GbgmFHu/TXgtVte4t60XQD8Op0QS5IkSZIkSS3SrS2Ej1bVKcPaeoeeVNVngc+ONLiq3gu8d1jbHcArRuh78rDz7wPPHtbtKOCiqvrZtkuXJEmSJEnSVOpWgNUaSf4OeCXwqrGOWbRgHgP9S7bdUZIkSZIkSRM25QFWVQ0CB09g/O6TVw1U1dsncz5JkiRJkiRNrm69A0uSJEmSJEkaEwMsSZIkSZIktZoBliRJkiRJklrNAEuSJEmSJEmtZoAlSZIkSZKkVjPAkiRJkiRJUqsZYEmSJEmSJKnVZne7gOlo3YaN9C5f1e0yZqTB/iXdLkGSJEmSJLVMV1dgJelNctMOnP+qHTW3JEmSJEmSpsaM3kJYVc/tdg2SJEmSJEmamDYEWLOSfDzJzUkuTfLEJIuTXJNkbZIvJ/l1gCSXJ+lrjp+cZLA5PijJtUnWNGMWNu33Nd9f2Iy9KMltSS5Ikubaq5q27yQ5J8nXu/JTkCRJkiRJ0ojaEGAtBD5aVQcBPwOOBT4F/LeqejawDvif25jjFODDVbUY6APuGqHPocA7gAOBfYHnJdkV+HvglVV1FDB/og8jSZIkSZKkydWGAOuOqlrTHK8G9gP2qqpvN22fBF6wjTmuBv57kv8GPKOqfj5Cn2ur6q6qehRYA/QCzwJ+WFV3NH3+ebQbJFmWZCDJwOYHNo7hsSRJkiRJkjQZ2hBgPTTkeDOw11b6PsIva951S2NVfRZ4NfBz4JIkLxrDfWYDGWuRVbWiqvqqqm/WbvPGOkySJEmSJEkT1IYAa7iNwP9N8vzm/I3AltVYg8DhzfFxWwYk2ZfOSqpzgJXAs8d4r9uAfZP0NufHb3/ZkiRJkiRJ2hFmd7uAUSwFzkuyG/BD4E1N+weBzyd5I3DZkP7HA29I8jDw78D7xnKTqvp5klOBi5P8BLh2sh5AkiRJkiRJkyNV1e0auirJ7lV1X/NXCT8K/KCqztramDk9C6tn6dlTUt/OZrB/SbdLkCRJkiRJXZBkdVX1jXStrSuwptIfJlkK/BpwA52/SrhVixbMY8CgRZIkSZIkaUrs9AFWs9pqqyuuJEmSJEmS1D1tfIm7JEmSJEmS9BgDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1Gqzu13AdLRuw0Z6l6/qdhk7vcH+Jd0uQZIkSZIkTYFpswIrydOSXLSV63slOXWs/SVJkiRJkjQ9TJsAq6rurqrjttJlL+CxAGsM/SVJkiRJkjQNdD3ASvKGJNcmWZPk75P8dpK1SXZNMjfJzUkOTtKb5KZmzEFDxqxNshDoB/Zr2s4c1v/kJF9KcnGSHyT52yH3f0uS7ye5PMnHk3ykOz8JSZIkSZIkjaSr78BKcgBwPPC8qno4ybnAbwErgb8Engh8pqpuStI7ZOgpwIer6oIkvwbMApYDB1fV4mbuof0BFgOHAg8B65P8HbAZeC9wGLAJuAy4cfKfVJIkSZIkSdur2y9xfzFwOHBdEugEVvcC7wOuAx4ETh9h3NXAe5LsDXypqn7QjN+ab1bVRoAktwDPAJ4MfLuqftq0fwHYf6TBSZYBywBm7Tl/HI8oSZIkSZKkiej2FsIAn6yqxc3Xb1XVGcCTgN2BPYBdhw+qqs8CrwZ+DlyS5EVjuNdDQ4430wnvtpl6Dbnniqrqq6q+WbvNG+swSZIkSZIkTVC3A6xvAscleQpAkicleQawgs7WvguAvxk+KMm+wA+r6hw62w2fTWcL4B7jvP+1wO8m+fUks4Fjt/tJJEmSJEmStEN0dQthVd2S5H8AlyZ5AvAw8FXgkar6bJJZwFXNCqsfDhl6PPCGJA8D/w68r6p+muS7zYvb/zfw0THcf0OSvwK+B9wN3AJsnMxnlCRJkiRJ0sSkqrpdQ1cl2b2q7mtWYH0Z+Meq+vLWxvT19dXAwMDUFChJkiRJkrQTSLK6qvpGutbtLYRtcEaSNcBNwB3AV7pajSRJkiRJkh6n23+FsOuq6l3drkGSJEmSJEmjcwWWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqtdndLmA6WrdhI73LV3W7DKnrBvuXdLsESZIkSdJOYEIrsJJctZ3jXpPkwDH0OyPJu5rj85Mctz33G0ddJyd52o68hyRJkiRJksZnQgFWVT13O4e+BthmgNUFJwMGWJIkSZIkSS0y0RVY9zXfX5jk8iQXJbktyQVJ0lzrT3JLkrVJPpjkucCrgTOTrEmyX5I/THJdkhuTfDHJbtu472CSv0pydZKBJIcluSTJvyY5ZUi/P23mXZvkL5q23iS3Jvl4kpuTXJrkic3qrj7ggqauJ07kZyNJkiRJkqTJMZkvcT8UeAedlVX7As9L8iTgtcBBVfVs4C+r6ipgJfCnVbW4qv4V+FJVHVFVhwC3Am8Zw/3urKrnAFcC5wPHAb8DvA8gycuAhcCRwGLg8CQvaMYuBD5aVQcBPwOOraqLgAHgpKaun0/khyFJkiRJkqTJMZkvcb+2qu4CSLIG6AWuAR4EPpFkFfD1UcYenOQvgb2A3YFLxnC/lc33dcDuVbUJ2JTkwSR7AS9rvm5o+u1OJ7j6P8AdVbWmaV/d1LpVSZYBywBm7Tl/DOVJkiRJkiRpMkzmCqyHhhxvBmZX1SN0VkB9kc57ry4eZez5wGlVtQj4C2DXcdzv0WH3fpROMBfgr5vVVIur6jer6h9Gq3VbN6uqFVXVV1V9s3abN4byJEmSJEmSNBkmM8D6FUl2B+ZV1f+is71wcXNpE7DHkK57APck2QU4aZJufwnw5qYGkixI8pRtjBlelyRJkiRJkrpsMrcQjmQP4KtJdqWzIuqdTfuFwMeTnE7n3VXvBb4H/BudLYETDpGq6tIkBwBXN++Tvw94A50VV6M5Hzgvyc+B5/geLEmSJEmSpO5LVXW7hmlnTs/C6ll6drfLkLpusH9Jt0uQJEmSJM0QSVZXVd9I13b0CqwZadGCeQz4D3dJkiRJkqQpsUPfgSVJkiRJkiRNlAGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktdrsbhcwkiSfAD5UVbcMaz8Z6Kuq07pSWGPdho30Ll/VzRKkVhrsX9LtEiRJkiRJM9CUBFhJAqSqHh1L/6r6rzu4JEmSJEmSJE0TO2wLYZLeJLcmORe4HnhvkuuSrE3yF02fuUlWJbkxyU1Jjm/aL0/S1xy/Kcn3k3wbeN6Q+ecn+WIz53VJnte0n5HkH5s5fpjk9CFj/qC5/41JPr21eSRJkiRJktQOO3oF1m8BbwK+AhwHHAkEWJnkBcB84O6qWgKQZN7QwUl6gL8ADgc2At8Cbmgufxg4q6q+k2Qf4BLggObas4CjgT2A9Uk+BuwPvAd4XlX9JMmTxjCPJEmSJEmSumxHB1j/VlXXJPkg8DJ+GT7tDiwErgQ+mORvgK9X1ZXDxv82cHlV/RggyefoBFEALwEO7OxOBGDPJHs0x6uq6iHgoST3Ak8FXgRcVFU/Aaiqn25tnqraNLSQJMuAZQCz9py/fT8NSZIkSZIkjduODrDub74H+Ouq+vvhHZIcDrwK+Oskl1bV+4Z1qVHmfgLwnKr6+bD5AB4a0rSZznNmlLlGnGe4qloBrACY07NwtJokSZIkSZI0yXbYO7CGuQR4c5LdAZIsSPKUJE8DHqiqzwAfBA4bNu57wAuT/EaSXYDXDbl2KfDYXyNMsngbNXwT+P0kv9H037KFcLzzSJIkSZIkaQpNyV8hrKpLkxwAXN2skLoPeAPwm8CZSR4FHgbeOmzcPUnOAK4G7qHzMvhZzeXTgY8mWds8xxXAKVup4eYkHwC+nWQzne2MJ493HkmSJEmSJE2tVLkbbrzm9CysnqVnd7sMqXUG+5d0uwRJkiRJ0jSVZHVV9Y10bUpWYM00ixbMY8B/qEuSJEmSJE2JqXoHliRJkiRJkrRdDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1WZ3u4DpaN2GjfQuX9XtMiQ1BvuXdLsESZIkSdIOtFOuwEpyX/P9aUkuao4XJ3lVdyuTJEmSJEnScDMmwEoy7tVkVXV3VR3XnC4GDLAkSZIkSZJaZlptIUzyB8C7gALWApuBnwKHAtcnORf4KDAfeAD4w6q6Lckzgc/Sed6Lh8zXC3wdOAx4H/DEJEcBf11Vn5uq55IkSZIkSdLopk2AleQg4D3A86rqJ0meBHwI2B94SVVtTvJN4JSq+kGS3wbOBV4EfBj4WFV9Ksnbhs9dVb9I8udAX1WdNmUPJUmSJEmSpG2aNgEWnSDqoqr6CUBV/TQJwBea8Gp34LnAF5p2gDnN9+cBxzbHnwb+Zrw3T7IMWAYwa8/52/sMkiRJkiRJGqfpFGCFztbB4e5vvj8B+FlVLR5l/Ehjx6yqVgArAOb0LJzQXJIkSZIkSRq76fQS928Cv5/kNwCaLYSPqar/BO5I8rrmepIc0lz+LnBCc3zSKPNvAvaY9KolSZIkSZI0IdMmwKqqm4EPAN9OciOd918NdxLwlub6zcAxTfsfAW9Lch0wb5RbfAs4MMmaJMdPbvWSJEmSJEnaXqlyN9x4zelZWD1Lz+52GZIag/1Lul2CJEmSJGmCkqyuqr6Rrk2nd2C1xqIF8xjwH8ySJEmSJElTYtpsIZQkSZIkSdLOyQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS12uxuFzAdrduwkd7lq7pdhqSWGexf0u0SJEmSJGlGmhErsJJ8IsmB3a5DkiRJkiRJk29GrMCqqv/a7RokSZIkSZK0Y3R9BVaSuUlWJbkxyU1Jjk/y50mua85XpOOAJNcOGdebZG1zfHmSvub4viQfaOa7JslTm/b9mvPrkrwvyX1Ne0+SK5Ksae73/G78HCRJkiRJkjSyrgdYwCuAu6vqkKo6GLgY+EhVHdGcPxH4vaq6Ffi1JPs2444HPj/CfHOBa6rqEOAK4A+b9g8DH66qI4C7h/Q/EbikqhYDhwBrJvXpJEmSJEmSNCFtCLDWAS9J8jdJnl9VG4Gjk3wvyTrgRcBBTd/PA7/fHB8PfG6E+X4BfL05Xg30NsfPAb7QHH92SP/rgDclOQNYVFWbRioyybIkA0kGNj+wcbzPKEmSJEmSpO3U9QCrqr4PHE4nyPrrJH8OnAscV1WLgI8DuzbdPwf8fpL9O0PrByNM+XBVVXO8mW2856uqrgBeAGwAPp3kD0bpt6Kq+qqqb9Zu88b3kJIkSZIkSdpuXQ+wkjwNeKCqPgN8EDisufSTJLsDx23pW1X/SieUei8jr77ammuAY5vjE4bc/xnAvVX1ceAfhtxfkiRJkiRJLdCGv0K4CDgzyaPAw8BbgdfQWZE1SGeL31CfA84EnjnO+7wD+EySPwFWAVv2Ab4Q+NMkDwP3ASOuwJIkSZIkSVJ35Je77Wa2JLsBP6+qSnIC8PqqOmZ75prTs7B6lp49qfVJmv4G+5d0uwRJkiRJmraSrK6qvpGutWEF1lQ5HPhIkgA/A968vRMtWjCPAf+hKkmSJEmSNCV2mgCrqq4EDul2HZIkSZIkSRqfrr/EXZIkSZIkSdoaAyxJkiRJkiS1mgGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqs7tdwHS0bsNGepev6nYZkqaJwf4l3S5BkiRJkqa1rq3ASnJft+49kiS9SU7sdh2SJEmSJEl6PLcQ/lIvYIAlSZIkSZLUMmMKsJK8Icm1SdYk+fsks5Lcl+RvkqxO8o0kRya5PMkPk7y6GXdykq8muTjJ+iT/c4S5k+TMJDclWZfk+Kb900mOGdLvgiSvbub8SpKvJbkjyWlJ/jjJDUmuSfKkpv9+zX1XJ7kyybOa9vOTnJPkqqbW45pb9APPb57xnRP7sUqSJEmSJGmybDPASnIAcDzwvKpaDGwGTgLmApdX1eHAJuAvgZcCrwXeN2SKI5v+i4HXJekbdov/0lw7BHgJcGaSHuATwJuaGuYBzwX+VzPmYDqrpY4EPgA8UFWHAlcDf9D0WQG8vanvXcC5Q+7ZAxwF/B6d4ApgOXBlVS2uqrO29XORJEmSJEnS1BjLS9xfDBwOXJcE4InAvcAvgIubPuuAh6rq4STr6GzH2+Jfquo/AJJ8iU5wNDDk+lHAP1fVZuBHSb4NHFFVK5N8NMlT6IRcX6yqR5oavlVVm4BNSTYCXxtSx7OT7E4n8PpC0x9gzpB7fqWqHgVuSfLUMfwMSLIMWAYwa8/5YxkiSZIkSZKkSTCWACvAJ6vq3Y9rTN5VVdWcPgo8BFBVjyYZOm/xeMPPw+g+TWf11gnAm4e0PzTk+NEh54/SeaYnAD9rVoyNZOj4rd3/MVW1gs6qLub0LBz+DJIkSZIkSdpBxvIOrG8CxzUroUjypCTPGMc9XtqMeSLwGuC7w65fARzfvFdrPvAC4Nrm2vnAOwCq6uax3rCq/hO4I8nrmpqT5JBtDNsE7DHWe0iSJEmSJGlqbDPAqqpbgP8BXJpkLfAvdN4hNVbfobOSag2dbYADw65/GVgL3AhcBvxZVf17c+8fAbcC/zSO+21xEvCWJDcCNwPHbKP/WuCRJDf6EndJkiRJkqT2yC93Ae6AyZOTgb6qOm07x+9G571Wh1XVxsmsbSLm9CysnqVnd7sMSdPEYP+SbpcgSZIkSa2XZHVVDf/jf8DY3oHVFUleAvwj8KE2hVcAixbMY8B/kEqSJEmSJE2JHRpgVdX5dN5jtT1jvwHsM5n1SJIkSZIkafoZy0vcJUmSJEmSpK4xwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS1mgGWJEmSJEmSWm12twuYjtZt2Ejv8lXdLkOSpCk12L+k2yVIkiRpJ9XqFVhJTk9ya5ILxjmuN8mJw9reneT2JOuTvHyEMSuT3DTRmiVJkiRJkjS52r4C61TglVV1xzjH9QInAp8FSHIgcAJwEPA04BtJ9q+qzc31/wLcN1lFS5IkSZIkafK0dgVWkvOAfYGVSd6T5B+TXJfkhiTHNH16k1yZ5Prm67nN8H7g+UnWJHkncAxwYVU91IRhtwNHNnPsDvwx8JdT/YySJEmSJEnattYGWFV1CnA3cDQwF7isqo5ozs9MMhe4F3hpVR0GHA+c0wxfDlxZVYur6ixgAXDnkOnvatoA3g/8f8ADO/iRJEmSJEmStB3avoVwi5cBr07yruZ8V2AfOgHXR5IsBjYD+48yPiO0VTPuN6vqnUl6t1ZAkmXAMoBZe84fb/2SJEmSJEnaTtMlwApwbFWtf1xjcgbwI+AQOqvJHhxl/F3A04ec700n/HoOcHiSQTo/i6ckubyqXjh8gqpaAawAmNOzsCbwLJIkSZIkSRqH1m4hHOYS4O1JApDk0KZ9HnBPVT0KvBGY1bRvAvYYMn4lcEKSOUmeCSwErq2qj1XV06qqFzgK+P5I4ZUkSZIkSZK6Z7oEWO8HdgHWJrmpOQc4F1ia5Bo62wfvb9rXAo8kuTHJO6vqZuDzwC3AxcDbtvwFQkmSJEmSJLVbqtwNN15zehZWz9Kzu12GJElTarB/SbdLkCRJ0gyWZHVV9Y10bbq8A6tVFi2Yx4C/xEuSJEmSJE2J6bKFUJIkSZIkSTspAyxJkiRJkiS1mgGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqtdndLmA6WrdhI73LV3W7DEmSptxg/5JulyBJkqSdUKtXYCU5PcmtSS4Y57jeJCcOa3t3ktuTrE/y8iHtr0+yLsnaJBcnefJk1S9JkiRJkqSJa3WABZwKvKqqThrnuF7gsQAryYHACcBBwCuAc5PMSjIb+DBwdFU9G1gLnDYZhUuSJEmSJGlytHYLYZLzgH2BlUkuBPYDFtGp+Yyq+mqSXuDTwNxm2GlVdRXQDxyQZA3wSWBX4MKqegi4I8ntwJHAABBgbpL/APYEbp+iR5QkSZIkSdIYtHYFVlWdAtwNHE0noLqsqo5ozs9MMhe4F3hpVR0GHA+c0wxfDlxZVYur6ixgAXDnkOnvAhZU1cPAW4F1zb0OBP5hhz+cJEmSJEmSxqy1AdYwLwOWNyuqLqezomofYBfg40nWAV+gE0CNJCO0VZJd6ARYhwJPo7OF8N0jTpAsSzKQZGDzAxsn8CiSJEmSJEkaj9ZuIRwmwLFVtf5xjckZwI+AQ+iEcQ+OMv4u4OlDzvems+JqMUBV/Wsz3+fprN76FVW1AlgBMKdnYW3fY0iSJEmSJGm8pssKrEuAtycJQJJDm/Z5wD1V9SjwRmBW074J2GPI+JXACUnmJHkmsBC4FtgAHJhkftPvpcCtO/RJJEmSJEmSNC7TZQXW+4GzgbVNiDUI/B5wLvDFJK8DvgXc3/RfCzyS5Ebg/Ko6q1lddQvwCPC2qtoM3J3kL4ArkjwM/Btw8pQ9lSRJkiRJkrYpVe6GG6++vr4aGBjodhmSJEmSJEkzRpLVVdU30rXpsoVQkiRJkiRJOykDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWq12d0uYDpat2EjvctXdbsMSZJaabB/SbdLkCRJ0gzT6hVYSU5PcmuSC8Y5rjfJicPa3p3k9iTrk7x8SPvFSW5McnOS85LMmqz6JUmSJEmSNHGtDrCAU4FXVdVJ4xzXCzwWYCU5EDgBOAh4BXDukKDq96vqEOBgYD7wuokWLUmSJEmSpMnT2i2ESc4D9gVWJrkQ2A9YRKfmM6rqq0l6gU8Dc5thp1XVVUA/cECSNcAngV2BC6vqIeCOJLcDRwJXV9V/NmNnA78G1FQ8nyRJkiRJksamtSuwquoU4G7gaDoB1WVVdURzfmaSucC9wEur6jDgeOCcZvhy4MqqWlxVZwELgDuHTH9X0wZAkkuauTYBF+3QB5MkSZIkSdK4tDbAGuZlwPJmRdXldFZU7QPsAnw8yTrgC8CBo4zPCG2PrbSqqpcDPcAc4EUjTpAsSzKQZGDzAxu38zEkSZIkSZI0Xq3dQjhMgGOrav3jGpMzgB8Bh9AJ4x4cZfxdwNOHnO9NZ3XXY6rqwSQrgWOAfxk+QVWtAFYAzOlZ6DZDSZIkSZKkKTJdVmBdArw9SQCSHNq0zwPuqapHgTcCW17MvgnYY8j4lcAJSeYkeSawELg2ye5Jepo5ZwOvAm7b4U8jSZIkSZKkMZsuAdb76WwXXJvkpuYc4FxgaZJrgP2B+5v2tcAjSW5M8s6quhn4PHALcDHwtqraTOfdWiuTrAVupPMerPOm6qEkSZIkSZK0balyN9x4zelZWD1Lz+52GZIktdJg/5JulyBJkqRpKMnqquob6dp0eQdWqyxaMI8BfzmXJEmSJEmaEtNlC6EkSZIkSZJ2UgZYkiRJkiRJajUDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1Gqzu13A1iQ5HXgrcH1VnTSOcb3Ac6vqs0Pa3g28BdgMnF5VlzTtxwPvAWYBq6rqz7Y1/7oNG+ldvmo8jyJJkoYZ7F/S7RIkSZI0TbR9BdapwKvGE141eoETt5wkORA4ATgIeAVwbpJZSX4DOBN4cVUdBDw1yYsnpXJJkiRJkiRNitauwEpyHrAvsDLJhcB+wCI6NZ9RVV9tVlp9GpjbDDutqq4C+oEDkqwBPgnsClxYVQ8BdyS5HTgSeAT4flX9uBn/DeBY4JtT8IiSJEmSJEkag9auwKqqU4C7gaPpBFSXVdURzfmZSeYC9wIvrarDgOOBc5rhy4Erq2pxVZ0FLADuHDL9XU3b7cCzkvQmmQ28Bnj6Dn84SZIkSZIkjVlrV2AN8zLg1Une1ZzvCuxDJ+D6SJLFdN5ttf8o4zNCW1XV/03yVuBzwKPAVXRWff3qBMkyYBnArD3nb+djSJIkSZIkabymS4AV4NiqWv+4xuQM4EfAIXRWkz04yvi7ePzKqr3phF9U1deArzXzLaMThP2KqloBrACY07OwtvM5JEmSJEmSNE6t3UI4zCXA25MEIMmhTfs84J6qehR4I52/JAiwCdhjyPiVwAlJ5iR5JrAQuLaZ6ynN91+n89L4T+zgZ5EkSZIkSdI4TJcA6/3ALsDaJDc15wDnAkuTXENn++D9Tfta4JEkNyZ5Z1XdDHweuAW4GHhbVW1ZafXhJLcA3wX6q+r7U/NIkiRJkiRJGotUuRtuvOb0LKyepWd3uwxJkqa1wf4l3S5BkiRJLZJkdVX1jXRturwDq1UWLZjHgL90S5IkSZIkTYnpsoVQkiRJkiRJOykDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWq12d0uYDpat2EjvctXdbsMSZKmtcH+Jd0uQZIkSdNEq1dgJTk9ya1JLhjnuN4kJw5re3eS25OsT/LyIe2/lmRFku8nuS3JsZNVvyRJkiRJkiau7SuwTgVeWVV3jHNcL3Ai8FmAJAcCJwAHAU8DvpFk/6raDLwHuLeq9k/yBOBJk1W8JEmSJEmSJq61AVaS84B9gZVJLgT2AxbRqfmMqvpqkl7g08DcZthpVXUV0A8ckGQN8ElgV+DCqnoIuCPJ7cCRwNXAm4FnAVTVo8BPpuYJJUmSJEmSNBat3UJYVacAdwNH0wmoLquqI5rzM5PMBe4FXlpVhwHHA+c0w5cDV1bV4qo6C1gA3Dlk+ruABUn2as7fn+T6JF9I8tQd/WySJEmSJEkau9YGWMO8DFjerKi6nM6Kqn2AXYCPJ1kHfAE4cJTxGaGt6Kzm2hv4bhOCXQ18cMQJkmVJBpIMbH5g4wQeRZIkSZIkSePR2i2EwwQ4tqrWP64xOQP4EXAInTDuwVHG3wU8fcj53nRWd/0H8ADw5ab9C8BbRpqgqlYAKwDm9Cys7XkISZIkSZIkjd90WYF1CfD2JAFIcmjTPg+4p3l31RuBWU37JmCPIeNXAickmZPkmcBC4NqqKuBrwAubfi8GbtmRDyJJkiRJkqTxmS4B1vvpbBdcm+Sm5hzgXGBpkmuA/YH7m/a1wCNJbkzyzqq6Gfg8nXDqYuBtzV8gBPhvwBlJ1tIJwf5kSp5IkiRJkiRJY5LOIiSNx5yehdWz9OxulyFJ0rQ22L+k2yVIkiSpRZKsrqq+ka5Nl3dgtcqiBfMY8JduSZIkSZKkKTFdthBKkiRJkiRpJ2WAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWo1AyxJkiRJkiS1mgGWJEmSJEmSWm12twuYjtZt2Ejv8lXdLkOSpBlhsH9Jt0uQJElSy7V6BVaS05PcmuSCcY7rTXLisLZ3J7k9yfokL2/a9kiyZsjXT5KcPYmPIEmSJEmSpAlq+wqsU4FXVtUd4xzXC5wIfBYgyYHACcBBwNOAbyTZv6o2AYu3DEqyGvjSxMuWJEmSJEnSZGltgJXkPGBfYGWSC4H9gEV0aj6jqr6apBf4NDC3GXZaVV0F9AMHJFkDfBLYFbiwqh4C7khyO3AkcPWQ+y0EngJcOQWPJ0mSJEmSpDFq7RbCqjoFuBs4mk5AdVlVHdGcn5lkLnAv8NKqOgw4HjinGb4cuLKqFlfVWcAC4M4h09/VtA31euBzVVU76pkkSZIkSZI0fq1dgTXMy4BXJ3lXc74rsA+dgOsjSRYDm4H9RxmfEdqGB1UnAG8crYAky4BlALP2nD/mwiVJkiRJkjQx0yXACnBsVa1/XGNyBvAj4BA6q8keHGX8XcDTh5zvTSf82jLPIcDsqlo9WgFVtQJYATCnZ6GrtCRJkiRJkqZIa7cQDnMJ8PYkAUhyaNM+D7inqh6ls3pqVtO+CdhjyPiVwAlJ5iR5JrAQuHbI9dcD/7wD65ckSZIkSdJ2mi4B1vuBXYC1SW5qzgHOBZYmuYbO9sH7m/a1wCNJbkzyzqq6Gfg8cAtwMfC2qto8ZP7fxwBLkiRJkiSpleI7y8dvTs/C6ll6drfLkCRpRhjsX9LtEiRJktQCSVZXVd9I16bLO7BaZdGCeQz4y7YkSZIkSdKUmC5bCCVJkiRJkrSTMsCSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktZoBliRJkiRJklrNAEuSJEmSJEmtZoAlSZIkSZKkVpvd7QKmo3UbNtK7fFW3y5Akaacw2L+k2yVIkiSpy1q9AivJ6UluTXLBOMf1JjlxWNu7k9yeZH2Slw9pv7xpW9N8PWWy6pckSZIkSdLEtX0F1qnAK6vqjnGO6wVOBD4LkORA4ATgIOBpwDeS7F9Vm5v+J1XVwOSULEmSJEmSpMnU2gAryXnAvsDKJBcC+wGL6NR8RlV9NUkv8GlgbjPstKq6CugHDkiyBvgksCtwYVU9BNyR5HbgSODqKXwkSZIkSZIkbYfWbiGsqlOAu4Gj6QRUl1XVEc35mUnmAvcCL62qw4DjgXOa4cuBK6tqcVWdBSwA7hwy/V1N2xb/1GwffG+S7NAHkyRJkiRJ0ri0dgXWMC8DXp3kXc35rsA+dAKujyRZDGwG9h9l/EihVDXfT6qqDUn2AL4IvBH41K9MkCwDlgHM2nP+dj6GJEmSJEmSxmu6BFgBjq2q9Y9rTM4AfgQcQmc12YOjjL8LePqQ873phF9U1Ybm+6Ykn6WztfBXAqyqWgGsAJjTs7CGX5ckSZIkSdKO0dothMNcArx9y/a+JIc27fOAe6rqUTorp2Y17ZuAPYaMXwmckGROkmcCC4Frk8xO8uRmzl2A3wNu2uFPI0mSJEmSpDGbLgHW+4FdgLVJbmrOAc4Flia5hs72wfub9rXAI0luTPLOqroZ+DxwC3Ax8LbmLxDOAS5JshZYA2wAPj5FzyRJkiRJkqQxSJW74carr6+vBgYGul2GJEmSJEnSjJFkdVX1jXRtuqzAkiRJkiRJ0k7KAEuSJEmSJEmtZoAlSZIkSZKkVjPAkiRJkiRJUqsZYEmSJEmSJKnVDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLWaAZYkSZIkSZJabXa3C5iO1m3YSO/yVd0uQ5IkaVoY7F/S7RIkSdI05wosSZIkSZIktZoBliRJkiRJklptRgZYSb6SZHWSm5Msa9rekuT7SS5P8vEkH2na5yf5YpLrmq/ndbd6SZIkSZIkDTVT34H15qr6aZInAtclWQW8FzgM2ARcBtzY9P0wcFZVfSfJPsAlwAHdKFqSJEmSJEm/aqYGWKcneW1z/HTgjcC3q+qnAEm+AOzfXH8JcGCSLWP3TLJHVW0aOmGzkmsZwKw95+/g8iVJkiRJkrTFjAuwkryQTij1nKp6IMnlwHpGX1X1hKbvz7c2b1WtAFYAzOlZWJNVryRJkiRJkrZuJr4Dax7wf5vw6lnA7wC7Ab+b5NeTzAaOHdL/UuC0LSdJFk9lsZIkSZIkSdq6mRhgXQzMTrIWeD9wDbAB+Cvge8A3gFuAjU3/04G+JGuT3AKcMvUlS5IkSZIkaTQzbgthVT0EvHJ4e5KBqlrRrMD6Mp2VV1TVT4Djp7ZKSZIkSZIkjdWMC7C24owkLwF2pRNefWV7J1q0YB4D/Usmqy5JkiRJkiRtxU4TYFXVu7pdgyRJkiRJksZvJr4DS5IkSZIkSTOIAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1GoGWJIkSZIkSWq12d0uIMkZwH1V9cEJzrMXcGJVnducPw04p6qOm3CRw6zbsJHe5asme1pJkqQZbbB/SbdLkCRJ09S0WoGVZGuB217AqVtOquruHRFeSZIkSZIkaWp1JcBK8p4k65N8A/itpu3yJH3N8ZOTDDbHJyf5QpKvAZcm2T3JN5Ncn2RdkmOaafuB/ZKsSXJmkt4kNzVz7Jrkn5r+NyQ5esjcX0pycZIfJPnbKf5RSJIkSZIkaRumfAthksOBE4BDm/tfD6zexrDnAM+uqp82q7BeW1X/meTJwDVJVgLLgYOranFzn94h498GUFWLkjyLThC2f3NtcVPLQ8D6JH9XVXdO/EklSZIkSZI0GbrxDqznA1+uqgcAmvBpW/6lqn7aHAf4qyQvAB4FFgBP3cb4o4C/A6iq25L8G7AlwPpmVW1sarkFeAbwKwFWkmXAMoBZe84fQ8mSJEmSJEmaDN16B1aN0PYIv6xn12HX7h9yfBIwHzi8WW31oxH6D5etXHtoyPFmRgn1qmpFVfVVVd+s3eZt43aSJEmSJEmaLN0IsK4AXpvkiUn2AP6fpn0QOLw53trL1+cB91bVw827rJ7RtG8C9tjKPU8CaLYO7gOs3+4nkCRJkiRJ0pSZ8gCrqq4HPgesAb4IXNlc+iDw1iRXAU/eyhQXAH1JBuiEUrc18/4H8N0kNyU5c9iYc4FZSdY19z65qh5CkiRJkiRJrZeqkXbzaWvm9CysnqVnd7sMSZKkaWWwf0m3S5AkSS2WZHVV9Y10rRsvcZ/2Fi2Yx4C/gEmSJEmSJE2Jbr3EXZIkSZIkSRoTAyxJkiRJkiS1mgGWJEmSJEmSWs0AS5IkSZIkSa1mgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqtdndLmA6WrdhI73LV3W7DEmSJElSCwz2L+l2CdKM19UVWEnOT3LcjponySeSHDjR+SVJkiRJktQ9M3oFVlX9127XIEmSJEmSpImZ0hVYSf4gydokNyb5dNP8giRXJfnh0FVUSf40yXVN/7/YxhxD7/H+ZkXWE5JcnqSvab8vyQeacdckeWrTvl9zfl2S9yW5bwf/GCRJkiRJkjQOUxZgJTkIeA/woqo6BPij5lIPcBTwe0B/0/dlwELgSGAxcHiSF2xlji33+FvgKcCbqurRYSXMBa5pxl0B/GHT/mHgw1V1BHD35D2xJEmSJEmSJsNUrsB6EXBRVf0EoKp+2rR/paoerapbgKc2bS9rvm4ArgeeRSfQGm0OgPcCe1XV/1tVNcL9fwF8vTleDfQ2x88BvtAcf3a04pMsSzKQZGDzAxvH+MiSJEmSJEmaqKkMsAKMFCw9NKzPlu9/XVWLm6/frKp/2MocANfRWan1pFGuPzwk2NrMON//VVUrqqqvqvpm7TZvPEMlSZIkSZI0AVMZYH0T+P0kvwGwlaAJ4BLgzUl2b/ouSPKUbcxxMZ0tiKuS7DGOuq4Bjm2OTxjHOEmSJEmSJE2BKfsrhFV1c5IPAN9OspnO9sDR+l6a5ADg6iQA9wFvGGWOk4eM+0ITXq1M8qoxlvYO4DNJ/gRYBbg/UJIkSZIkqUUy8uuidh5JdgN+XlWV5ATg9VV1zNbGzOlZWD1Lz56S+iRJkiRJ7TbYv6TbJUgzQpLVVdU30rUpW4HVYocDH0lnqdfPgDdva8CiBfMY8H+gJEmSJEmSpsROH2BV1ZXAId2uQ5IkSZIkSSObype4S5IkSZIkSeNmgCVJkiRJkqRWM8CSJEmSJElSqxlgSZIkSZIkqdUMsCRJkiRJktRqBliSJEmSJElqNQMsSZIkSZIktdrsbhcwHa3bsJHe5au6XYYkSZIkSVNisH9Jt0vQTq7VK7CSnJ7k1iQXjHNcb5ITh7W9O8ntSdYnefmQ9g8kuTPJfZNVtyRJkiRJkiZPqwMs4FTgVVV10jjH9QKPBVhJDgROAA4CXgGcm2RWc/lrwJETL1WSJEmSJEk7Qmu3ECY5D9gXWJnkQmA/YBGdms+oqq8m6QU+Dcxthp1WVVcB/cABSdYAnwR2BS6sqoeAO5LcTie0urqqrmnuN2XPJkmSJEmSpLFr7QqsqjoFuBs4mk5AdVlVHdGcn5lkLnAv8NKqOgw4HjinGb4cuLKqFlfVWcAC4M4h09/VtEmSJEmSJKnlWrsCa5iXAa9O8q7mfFdgHzoB10eSLAY2A/uPMn6k5VU1ngKSLAOWAczac/54hkqSJEmSJGkCpkuAFeDYqlr/uMbkDOBHwCF0VpM9OMr4u4CnDznfm074NWZVtQJYATCnZ+G4wi9JkiRJkiRtv9ZuIRzmEuDtaV5UleTQpn0ecE9VPQq8EdjyYvZNwB5Dxq8ETkgyJ8kzgYXAtVNSuSRJkiRJkiZkugRY7wd2AdYmuak5BzgXWJrkGjrbB+9v2tcCjyS5Mck7q+pm4PPALcDFwNuqajNAkr9NchewW5K7mlVdkiRJkiRJaolUuRtuvOb0LKyepWd3uwxJkiRJkqbEYP+SbpegnUCS1VXVN9K16fIOrFZZtGAeA354JUmSJEmSpsR02UIoSZIkSZKknZQBliRJkiRJklrNAEuSJEmSJEmtZoAlSZIkSZKkVjPAkiRJkiRJUqsZYEmSJEmSJKnVDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLXa7G4XMB2t27CR3uWrul2GJEmSJElTarB/SbdL0E6q1Suwkpye5NYkF4xzXG+SE4ec/0aSbyW5L8lHhvU9PMm6JLcnOSdJJqt+SZIkSZIkTVyrAyzgVOBVVXXSOMf1AicOOX8QeC/wrhH6fgxYBixsvl4x/jIlSZIkSZK0o7Q2wEpyHrAvsDLJe5L8Y5LrktyQ5JimT2+SK5Nc33w9txneDzw/yZok76yq+6vqO3SCrKH36AH2rKqrq6qATwGvmbKHlCRJkiRJ0ja1NsCqqlOAu4GjgbnAZVV1RHN+ZpK5wL3AS6vqMOB44Jxm+HLgyqpaXFVnbeU2C4C7hpzf1bRJkiRJkiSpJabLS9xfBrw6yZYtgLsC+9AJuD6SZDGwGdh/nPOO9L6rGrFjsozOVkNm7Tl/nLeRJEmSJEnS9pouAVaAY6tq/eMakzOAHwGH0FlN9uCvDt2qu4C9h5zvTScU+xVVtQJYATCnZ+GIIZckSZIkSZImX2u3EA5zCfD2LX8hMMmhTfs84J6qehR4IzCrad8E7LGtSavqHmBTkt9p5v4D4KuTXbwkSZIkSZK233QJsN4P7AKsTXJTcw5wLrA0yTV0tg/e37SvBR5JcmOSdwIkGQQ+BJyc5K4kBzZ93wp8Argd+Ffgf0/B80iSJEmSJGmMWr2FsKp6h5z+vyNc/wHw7CFN727aHwZevJW5hrYPAAdPsFRJkiRJkiTtIK0OsNpq0YJ5DPQv6XYZkiRJkiRJO4XpsoVQkiRJkiRJOykDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrWaAJUmSJEmSpFYzwJIkSZIkSVKrGWBJkiRJkiSp1QywJEmSJEmS1Gqzu13AdLRuw0Z6l6/qdhmSJEmSJGknNdi/pNslTKlWr8BKcnqSW5NcMM5xvUlOHNb27iS3J1mf5OVN225JViW5LcnNSfons35JkiRJkiRNXKsDLOBU4FVVddI4x/UCjwVYSQ4ETgAOAl4BnJtkVnP5g1X1LOBQ4HlJXjnhqiVJkiRJkjRpWruFMMl5wL7AyiQXAvsBi+jUfEZVfTVJL/BpYG4z7LSqugroBw5Isgb4JLArcGFVPQTckeR24Miquhr4FkBV/SLJ9cDeU/WMkiRJkiRJ2rbWrsCqqlOAu4Gj6QRUl1XVEc35mUnmAvcCL62qw4DjgXOa4cuBK6tqcVWdBSwA7hwy/V1N22OS7AX8P8A3d9hDSZIkSZIkadxauwJrmJcBr07yruZ8V2AfOgHXR5IsBjYD+48yPiO01WMXk9nAPwPnVNUPR5wgWQYsA5i15/zteARJkiRJkiRtj+kSYAU4tqrWP64xOQP4EXAIndVkD44y/i7g6UPO96YTfm2xAvhBVZ09WgFVtaLpx5yehTVaP0mSJEmSJE2u1m4hHOYS4O1JApDk0KZ9HnBPVT0KvBHY8mL2TcAeQ8avBE5IMifJM4GFwLXNXH/ZzPOOHf0QkiRJkiRJGr/pEmC9H9gFWJvkpuYc4FxgaZJr6GwfvL9pXws8kuTGJO+sqpuBzwO3ABcDb6uqzUn2Bt4DHAhcn2RNkv86dY8lSZIkSZKkbUmVu+HGa07PwupZena3y5AkSZIkSTupwf4l3S5h0iVZXVV9I12bLu/AapVFC+YxMAP/D0WSJEmSJKmNpssWQkmSJEmSJO2kDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLWaf4VwOyTZBKzvdh2SJs2TgZ90uwhJk8rPtTTz+LmWZhY/0xrJM6pq/kgX/CuE22f9aH/WUdL0k2TAz7Q0s/i5lmYeP9fSzOJnWuPlFkJJkiRJkiS1mgGWJEmSJEmSWs0Aa/us6HYBkiaVn2lp5vFzLc08fq6lmcXPtMbFl7hLkiRJkiSp1VyBJUmSJEmSpFYzwBoiySuSrE9ye5LlI1xPknOa62uTHDbWsZK6Y3s/10menuRbSW5NcnOSP5r66iUNN5H/VjfXZyW5IcnXp65qSVszwd/B90pyUZLbmv9mP2dqq5c0kgl+rt/Z/P59U5J/TrLr1FavtjLAaiSZBXwUeCVwIPD6JAcO6/ZKYGHztQz42DjGSppiE/lcA48Af1JVBwC/A7zNz7XUXRP8TG/xR8CtO7hUSWM0CZ/rDwMXV9WzgEPw8y113QT/bb0AOB3oq6qDgVnACVNUulrOAOuXjgRur6ofVtUvgAuBY4b1OQb4VHVcA+yVpGeMYyVNve3+XFfVPVV1PUBVbaLzC/GCqSxe0q+YyH+rSbI3sAT4xFQWLWmrtvtznWRP4AXAPwBU1S+q6mdTWLukkU3ov9fAbOCJSWYDuwF3T1XhajcDrF9aANw55PwufvUfq6P1GctYSVNvIp/rxyTpBQ4Fvjf5JUoah4l+ps8G/gx4dAfVJ2n8JvK53hf4MfBPzdbgTySZuyOLlTQm2/25rqoNwAeB/wPcA2ysqkt3YK2aRgywfikjtA3/E42j9RnLWElTbyKf687FZHfgi8A7quo/J7E2SeO33Z/pJL8H3FtVqye/LEkTMJH/Vs8GDgM+VlWHAvcDvotW6r6J/Pf61+msznom8DRgbpI3THJ9mqYMsH7pLuDpQ8735leXKo7WZyxjJU29iXyuSbILnfDqgqr60g6sU9LYTOQz/Tzg1UkG6WxleFGSz+y4UiWN0UR/B7+rqraskL6ITqAlqbsm8rl+CXBHVf24qh4GvgQ8dwfWqmnEAOuXrgMWJnlmkl+j86K4lcP6rAT+oPmLCb9DZznjPWMcK2nqbffnOknovFPj1qr60NSWLWkU2/2Zrqp3V9XeVdXbjLusqvz/6ErdN5HP9b8Ddyb5rabfi4FbpqxySaOZyL+t/w/wO0l2a34ffzH+cQY1Zne7gLaoqkeSnAZcQucvHfxjVd2c5JTm+nnA/wJeBdwOPAC8aWtju/AYkoaYyOeazmqNNwLrkqxp2v57Vf2vKXwESUNM8DMtqYUm4XP9duCC5h/JP8TPvNR1E/y39feSXARcT+evgt8ArJj6p1AbpcpXNUmSJEmSJKm93EIoSZIkSZKkVjPAkiRJkiRJUqsZYEmSJEmSJKnVDLAkSZIkSZLUagZYkiRJkiRJajUDLEmSJEmSJLWaAZYkSZIkSZJazQBLkiRJkiRJrfb/A3UxaDeRpbR+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_numeric, y)\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "pd.Series(rf.feature_importances_, index=X_train_numeric.columns).groupby(lambda x: x.split('_')[0]).mean().sort_values(ascending=False).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01083d6f7d6e156",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Installment commitement seems like nice cutoff point. in case feat importance < installment and mutual info < 0.01, we will drop the feature\n",
    "`feats_to_drop = ['purpose', 'personal_status', 'own_telephone', 'housing', 'existing_credits', 'job', 'other_parties', 'property_magnitude']`\n",
    "We can somewhat justify dropping these features:\n",
    "- purpose: we know the credit amount, so we can somewhat infer the purpose of the credit\n",
    "- personal_status: this information might not be that important, as we have information about the number of dependents\n",
    "- own_telephone: this information doesnt seem to be related with the credit risk\n",
    "- housing: most of the people have their own housing, so this information doesnt seem to be related with the credit risk. although it might play a role when defaulting - people with houses have property to lose - so the feature will stay\n",
    "- existing_credits: this information is correlated with installment commitement. though, it might give us some information when in an interaction with another variable\n",
    "- job: i cant reasonably justify dropping this feature - it will stay\n",
    "- other_parties: it seems like only a fraction of people have other parties involved in the credit, and this doesnt seem to be related with the credit risk\n",
    "- property_magnitude: i cant reasonably justify dropping this feature - it will stay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933ba994dec24097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T16:20:32.512725Z",
     "start_time": "2023-12-09T16:20:32.467173Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats_to_drop = ['purpose', 'personal_status', 'own_telephone', 'other_parties']\n",
    "x = x.drop(columns=feats_to_drop)\n",
    "x_out_of_sample = x_out_of_sample.drop(columns=feats_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ccb85d537f24e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we will define a pipeline for model training and evaluation. \n",
    "For numerical variables, we will use RobustScaler.\n",
    "For categorical variables, we will use OneHotEncoder for encoding purposes, for the models to handle our categorical variables.\n",
    "Then, we will have RandomizedSearchCV for hyperparameter tuning, with StratifiedKFold cross validation.\n",
    "In our models, we will focus on imbalanced problem, so we choose average precision score as our scoring metric, due to the fact that it is not sensitive to class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0727c8660fd989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T16:45:46.122654Z",
     "start_time": "2023-12-09T16:45:45.972744Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def get_pipeline_for_model(\n",
    "    model, model_params: dict = None\n",
    "):\n",
    "    numerical_prep = make_pipeline(RobustScaler())\n",
    "    categorical_prep = make_pipeline(\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse=False, drop=\"first\"),\n",
    "    )\n",
    "    preprocess = ColumnTransformer(\n",
    "        [\n",
    "            (\n",
    "                \"numerical\",\n",
    "                numerical_prep,\n",
    "                make_column_selector(dtype_include=[\"int64\", \"float64\"]),\n",
    "            ),\n",
    "            (\n",
    "                \"categorical\",\n",
    "                categorical_prep,\n",
    "                make_column_selector(dtype_include=object),\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    preprocess.set_output(transform=\"pandas\")\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"model\", model(**model_params if model_params else {})),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad708bc91cfbdd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T16:48:23.473955Z",
     "start_time": "2023-12-09T16:48:23.191568Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OneModelHyperoptResult:\n",
    "    best_model: BaseEstimator\n",
    "    best_score: float\n",
    "    cv_results: pd.DataFrame\n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        return self.best_model[\"model\"].__class__.__name__\n",
    "\n",
    "@dataclass\n",
    "class HyperoptInput:\n",
    "    model: BaseEstimator\n",
    "    hyperopt_space: dict = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class HyperoptResults:\n",
    "    results: list\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._sort_by_best_score()\n",
    "\n",
    "    def _sort_by_best_score(self, reversed: bool = True):\n",
    "        self.results.sort(key=lambda x: x.best_score, reverse=reversed)\n",
    "\n",
    "    def get_best_model(self):\n",
    "        return self.results[0].best_model\n",
    "\n",
    "    def get_best_score(self):\n",
    "        return self.results[0].best_score\n",
    "\n",
    "    def get_merged_df(self):\n",
    "        results = pd.DataFrame()\n",
    "        for result in self.results:\n",
    "            results = pd.concat(\n",
    "                [\n",
    "                    results,\n",
    "                    result.cv_results.assign(\n",
    "                        model_name=result.get_model_name()\n",
    "                    ),\n",
    "                ],\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_all_dfs(self):\n",
    "        return [\n",
    "            (result.get_model_name(), result.cv_results)\n",
    "            for result in self.results\n",
    "        ]\n",
    "\n",
    "    def get_all_scores(self):\n",
    "        return [\n",
    "            (result.get_model_name(), result.best_score)\n",
    "            for result in self.results\n",
    "        ]\n",
    "\n",
    "    def get_all_models(self):\n",
    "        return [\n",
    "            (result.get_model_name(), result.best_model)\n",
    "            for result in self.results\n",
    "        ]\n",
    "\n",
    "def run_hyperopt_one_model(\n",
    "    x: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    model_input: HyperoptInput,\n",
    "    n_iter: int = 10,\n",
    "    cv: int = 5,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    pipeline = get_pipeline_for_model(model_input.model)\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        model_input.hyperopt_space,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"average_precision\",\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    search.fit(x, y)\n",
    "    return OneModelHyperoptResult(\n",
    "        best_model=search.best_estimator_,\n",
    "        best_score=search.best_score_,\n",
    "        cv_results=pd.DataFrame(search.cv_results_),\n",
    "    )\n",
    "def run_hyperopt(\n",
    "    hyperopt_inputs: list,\n",
    "    n_iter: int = 10,\n",
    "    cv: int = 5,\n",
    "    random_state: int = 42,\n",
    ") -> HyperoptResults:\n",
    "    results = []\n",
    "    for model_input in hyperopt_inputs:\n",
    "        logger.info(f\"Running hyperopt for {model_input.model.__name__}\")\n",
    "        result = run_hyperopt_one_model(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            model_input=model_input,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        results.append(result)\n",
    "        logger.info(f\"Best score: {result.best_score}\")\n",
    "    return HyperoptResults(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea96e966f8b915b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T17:07:21.577726Z",
     "start_time": "2023-12-09T17:07:21.544297Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2388663967611335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight = y.value_counts()[0] / y.value_counts()[1]\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b96fd0bce8d2cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:00:54.363797Z",
     "start_time": "2023-12-09T18:48:51.941822Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "base_hyperopt_inputs = [\n",
    "    HyperoptInput(\n",
    "        model=RandomForestClassifier,\n",
    "        hyperopt_space={\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__n_estimators\": randint(50, 500),\n",
    "            \"model__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            \"model__max_depth\": randint(3, 9),\n",
    "            \"model__min_samples_split\": uniform(0.01, 0.04),\n",
    "            \"model__class_weight\": [\"balanced\"],\n",
    "            \"model__max_samples\": uniform(0.7, 0.2),\n",
    "        },\n",
    "    ),\n",
    "    HyperoptInput(\n",
    "        model=XGBClassifier,\n",
    "        hyperopt_space={\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__n_estimators\": randint(50, 500),\n",
    "            \"model__max_depth\": randint(4, 10),\n",
    "            \"model__learning_rate\": uniform(0.01, 0.29),\n",
    "            \"model__subsample\": uniform(0.8, 0.2),\n",
    "            \"model__colsample_bytree\": uniform(0.6, 0.3),\n",
    "            \"model__scale_pos_weight\": [pos_weight],\n",
    "            \"model__gamma\": uniform(0, 5),\n",
    "            \"model__lambda\": uniform(0, 5),\n",
    "            \"model__alpha\": uniform(0, 5),\n",
    "            \"model__grow_policy\": [\"lossguide\", \"depthwise\"],\n",
    "        },\n",
    "    ),\n",
    "    HyperoptInput(\n",
    "        model=ExtraTreesClassifier,\n",
    "        hyperopt_space={\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            \"model__n_estimators\": randint(50, 500),\n",
    "            \"model__max_depth\": randint(3, 9),\n",
    "            \"model__min_samples_split\": uniform(0.01, 0.04),\n",
    "            \"model__class_weight\": [\"balanced\"],\n",
    "        },\n",
    "    ),\n",
    "    HyperoptInput(\n",
    "        model=LGBMClassifier,\n",
    "    hyperopt_space={\n",
    "        \"model__n_jobs\": [-1],\n",
    "        \"model__boosting_type\": [\"gbdt\", \"dart\"],\n",
    "        \"model__n_estimators\": randint(50, 500),\n",
    "        \"model__class_weight\": ['balanced'],\n",
    "        \"model__learning_rate\": uniform(0.01, 0.29),\n",
    "        \"model__subsample\": uniform(0.8, 0.2),\n",
    "        \"model__colsample_bytree\": uniform(0.6, 0.3),\n",
    "        \"model__reg_alpha\": uniform(0, 5),\n",
    "        \"model__reg_lambda\": uniform(0, 5),\n",
    "    })\n",
    "]\n",
    "s_cv = StratifiedKFold(n_splits=5)\n",
    "results = run_hyperopt(base_hyperopt_inputs, n_iter=50, cv=s_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897836258422a7df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a02746ad5dd3d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:01:44.122231Z",
     "start_time": "2023-12-09T19:01:44.028624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__class_weight</th>\n",
       "      <th>param_model__criterion</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__n_jobs</th>\n",
       "      <th>...</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>param_model__grow_policy</th>\n",
       "      <th>param_model__lambda</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__scale_pos_weight</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>param_model__boosting_type</th>\n",
       "      <th>param_model__reg_alpha</th>\n",
       "      <th>param_model__reg_lambda</th>\n",
       "      <th>param_model__max_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.551782</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.129434</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>156</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.270045</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>0.143669</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>264</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559594</td>\n",
       "      <td>0.052444</td>\n",
       "      <td>0.110063</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>0.044647</td>\n",
       "      <td>149</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642170</td>\n",
       "      <td>0.029214</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>8</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>393</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.286185</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.233868</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>493</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.168266</td>\n",
       "      <td>0.184362</td>\n",
       "      <td>0.229850</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>490</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.149349</td>\n",
       "      <td>0.198277</td>\n",
       "      <td>0.083908</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>0.045094</td>\n",
       "      <td>148</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.879902</td>\n",
       "      <td>0.180565</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>0.049287</td>\n",
       "      <td>109</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.608769</td>\n",
       "      <td>0.043772</td>\n",
       "      <td>0.069878</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048617</td>\n",
       "      <td>86</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.158329</td>\n",
       "      <td>0.054107</td>\n",
       "      <td>0.122941</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>257</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.551782      0.043489         0.129434        0.026726   \n",
       "1        1.270045      0.092235         0.143669        0.011074   \n",
       "2        0.559594      0.052444         0.110063        0.006633   \n",
       "3        1.642170      0.029214         0.200820        0.018869   \n",
       "4        2.286185      0.215443         0.233868        0.016632   \n",
       "..            ...           ...              ...             ...   \n",
       "45       3.168266      0.184362         0.229850        0.018919   \n",
       "46       1.149349      0.198277         0.083908        0.006401   \n",
       "47       0.879902      0.180565         0.075062        0.005055   \n",
       "48       0.608769      0.043772         0.069878        0.012535   \n",
       "49       1.158329      0.054107         0.122941        0.013247   \n",
       "\n",
       "   param_model__class_weight param_model__criterion param_model__max_depth  \\\n",
       "0                   balanced               log_loss                      6   \n",
       "1                   balanced                   gini                      7   \n",
       "2                   balanced               log_loss                      5   \n",
       "3                   balanced               log_loss                      8   \n",
       "4                   balanced                entropy                      8   \n",
       "..                       ...                    ...                    ...   \n",
       "45                  balanced               log_loss                      4   \n",
       "46                  balanced                   gini                      4   \n",
       "47                  balanced               log_loss                      6   \n",
       "48                  balanced                   gini                      4   \n",
       "49                  balanced               log_loss                      3   \n",
       "\n",
       "   param_model__min_samples_split param_model__n_estimators  \\\n",
       "0                        0.048029                       156   \n",
       "1                        0.016241                       264   \n",
       "2                        0.044647                       149   \n",
       "3                        0.012256                       393   \n",
       "4                        0.010031                       493   \n",
       "..                            ...                       ...   \n",
       "45                       0.037028                       490   \n",
       "46                       0.045094                       148   \n",
       "47                       0.049287                       109   \n",
       "48                       0.048617                        86   \n",
       "49                       0.038014                       257   \n",
       "\n",
       "   param_model__n_jobs  ... param_model__gamma  param_model__grow_policy  \\\n",
       "0                   -1  ...                NaN                       NaN   \n",
       "1                   -1  ...                NaN                       NaN   \n",
       "2                   -1  ...                NaN                       NaN   \n",
       "3                   -1  ...                NaN                       NaN   \n",
       "4                   -1  ...                NaN                       NaN   \n",
       "..                 ...  ...                ...                       ...   \n",
       "45                  -1  ...                NaN                       NaN   \n",
       "46                  -1  ...                NaN                       NaN   \n",
       "47                  -1  ...                NaN                       NaN   \n",
       "48                  -1  ...                NaN                       NaN   \n",
       "49                  -1  ...                NaN                       NaN   \n",
       "\n",
       "    param_model__lambda  param_model__learning_rate  \\\n",
       "0                   NaN                         NaN   \n",
       "1                   NaN                         NaN   \n",
       "2                   NaN                         NaN   \n",
       "3                   NaN                         NaN   \n",
       "4                   NaN                         NaN   \n",
       "..                  ...                         ...   \n",
       "45                  NaN                         NaN   \n",
       "46                  NaN                         NaN   \n",
       "47                  NaN                         NaN   \n",
       "48                  NaN                         NaN   \n",
       "49                  NaN                         NaN   \n",
       "\n",
       "    param_model__scale_pos_weight  param_model__subsample  \\\n",
       "0                             NaN                     NaN   \n",
       "1                             NaN                     NaN   \n",
       "2                             NaN                     NaN   \n",
       "3                             NaN                     NaN   \n",
       "4                             NaN                     NaN   \n",
       "..                            ...                     ...   \n",
       "45                            NaN                     NaN   \n",
       "46                            NaN                     NaN   \n",
       "47                            NaN                     NaN   \n",
       "48                            NaN                     NaN   \n",
       "49                            NaN                     NaN   \n",
       "\n",
       "    param_model__boosting_type  param_model__reg_alpha  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "3                          NaN                     NaN   \n",
       "4                          NaN                     NaN   \n",
       "..                         ...                     ...   \n",
       "45                         NaN                     NaN   \n",
       "46                         NaN                     NaN   \n",
       "47                         NaN                     NaN   \n",
       "48                         NaN                     NaN   \n",
       "49                         NaN                     NaN   \n",
       "\n",
       "    param_model__reg_lambda param_model__max_samples  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                       NaN                      NaN  \n",
       "4                       NaN                      NaN  \n",
       "..                      ...                      ...  \n",
       "45                      NaN                 0.867542  \n",
       "46                      NaN                 0.884939  \n",
       "47                      NaN                 0.734991  \n",
       "48                      NaN                 0.899251  \n",
       "49                      NaN                 0.755774  \n",
       "\n",
       "[200 rows x 32 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_merged_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34eccf72cc49bd9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:04:07.078776Z",
     "start_time": "2023-12-09T19:04:06.998552Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ExtraTreesClassifier', 0.7976447599660041),\n",
       " ('XGBClassifier', 0.7974518875540617),\n",
       " ('LGBMClassifier', 0.7816934914571763),\n",
       " ('RandomForestClassifier', 0.7571002087648209)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_all_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c1036c06b92ec2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:04:24.440926Z",
     "start_time": "2023-12-09T19:04:24.329726Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;robustscaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0be0&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0310&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 ExtraTreesClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                      criterion=&#x27;log_loss&#x27;, max_depth=8,\n",
       "                                      min_samples_split=0.010020815079812633,\n",
       "                                      n_estimators=282, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;robustscaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0be0&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0310&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 ExtraTreesClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                      criterion=&#x27;log_loss&#x27;, max_depth=8,\n",
       "                                      min_samples_split=0.010020815079812633,\n",
       "                                      n_estimators=282, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;robustscaler&#x27;,\n",
       "                                                  RobustScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0be0&gt;),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0310&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0be0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0310&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;log_loss&#x27;, max_depth=8,\n",
       "                     min_samples_split=0.010020815079812633, n_estimators=282,\n",
       "                     n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(steps=[('robustscaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0be0>),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fd1a43c0310>)])),\n",
       "                ('model',\n",
       "                 ExtraTreesClassifier(class_weight='balanced',\n",
       "                                      criterion='log_loss', max_depth=8,\n",
       "                                      min_samples_split=0.010020815079812633,\n",
       "                                      n_estimators=282, n_jobs=-1))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = results.get_best_model()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9ca399601e8a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model evaluation on out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "75bc698af612920c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:14:20.275982Z",
     "start_time": "2023-12-09T19:14:20.244098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, precision_score\n",
    "@dataclass\n",
    "class ClassificationScores:\n",
    "    au_roc: float\n",
    "    au_prc: float\n",
    "    f1: float\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "\n",
    "def get_classification_scores(\n",
    "    model: BaseEstimator, x: pd.DataFrame, y: pd.Series\n",
    ") -> ClassificationScores:\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred_proba = model.predict_proba(x)[:, 1]\n",
    "    return ClassificationScores(\n",
    "        au_roc=roc_auc_score(y, y_pred_proba),\n",
    "        au_prc=average_precision_score(y, y_pred_proba),\n",
    "        f1=f1_score(y, y_pred),\n",
    "        accuracy=accuracy_score(y, y_pred),\n",
    "        precision=precision_score(y, y_pred),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "80a501fdb5dd99fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:22:45.959873Z",
     "start_time": "2023-12-09T19:22:45.526072Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>au_roc</th>\n",
       "      <td>0.865971</td>\n",
       "      <td>0.892327</td>\n",
       "      <td>0.892093</td>\n",
       "      <td>0.862962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au_prc</th>\n",
       "      <td>0.783787</td>\n",
       "      <td>0.798993</td>\n",
       "      <td>0.803246</td>\n",
       "      <td>0.740527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.669291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.694656</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ExtraTreesClassifier  XGBClassifier  LGBMClassifier  \\\n",
       "au_roc                 0.865971       0.892327        0.892093   \n",
       "au_prc                 0.783787       0.798993        0.803246   \n",
       "f1                     0.708955       0.713725        0.715447   \n",
       "accuracy               0.805000       0.817500        0.825000   \n",
       "precision              0.659722       0.694656        0.721311   \n",
       "\n",
       "           RandomForestClassifier  \n",
       "au_roc                   0.862962  \n",
       "au_prc                   0.740527  \n",
       "f1                       0.669291  \n",
       "accuracy                 0.790000  \n",
       "precision                0.653846  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_stats = {}\n",
    "for i in range(4):\n",
    "    models_stats[results.results[i].get_model_name()] = get_classification_scores(results.results[i].best_model, x_out_of_sample, y_out_of_sample)\n",
    "models_stats = {k: [v.au_roc, v.au_prc, v.f1, v.accuracy, v.precision] for k, v in models_stats.items()}\n",
    "index = ['au_roc', 'au_prc', 'f1', 'accuracy', 'precision']\n",
    "models_stats = pd.DataFrame(models_stats, index=index)\n",
    "pd.DataFrame(models_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda685da7dea159",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Interestingly, on training set, ExtraTreesClassifier had the best score, beating boosting methods - XGB and LightGBM by a small margin. Though, when it comes to out of sample data, the boosting methods are better than ExtraTreesClassifier. This suggests that the Boosting methods generalized better than ExtraTreesClassifier. Let us have an insight into XGB and LGBM hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "21c854680420d9e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:32:50.929482Z",
     "start_time": "2023-12-09T19:32:50.911814Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "{'colsample_bytree': 0.6956926890881283, 'gamma': 4.2243765548472725, 'grow_policy': 'depthwise', 'learning_rate': 0.0856014131884119, 'max_depth': 7, 'n_estimators': 363, 'subsample': 0.9393474330728302, 'alpha': 0.35594324230114494, 'lambda': 1.7031228473212001} \n",
      "\n",
      "\n",
      "LGBMClassifier\n",
      "{'boosting_type': 'dart', 'colsample_bytree': 0.7345272428958742, 'importance_type': 'split', 'learning_rate': 0.298392664157138, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 210, 'num_leaves': 31, 'reg_alpha': 0.09037681807760434, 'reg_lambda': 2.469468575917173, 'subsample': 0.8357645418442659, 'subsample_for_bin': 200000, 'subsample_freq': 0} \n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(results.results[i].get_model_name())\n",
    "    param_dct = {}\n",
    "    for param, value in results.results[i].best_model['model'].get_params().items():\n",
    "        if value is not None and param not in ['objective', 'enable_categorical', 'missing', 'n_jobs', 'scale_pos_weight', 'class_weight']:\n",
    "            param_dct[param] = value\n",
    "            \n",
    "    print(f'{param_dct} \\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c9d1e72a9c80e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To summarize both model hyperparameters:\n",
    "- both models used around 70% of features for each tree - good for building diverse trees\n",
    "- the way that nodes were added to the tree was different - XGB used depthwise, while LGBM used lossguide. This means that in XGB, the splits were mode from nodes closest to the root, while in LGBM, the splits were at nodes with the highest loss change. Though, we have made an effort to control the overfitting by setting max_depth in XGB and max_leaves in LGBM.\n",
    "- both models have used a few hundred trees\n",
    "- both models have sampled about 80% of the data for each tree - good for building diverse trees (we still used CV to control overfitting)\n",
    "- both models have used L1 and L2 regularization \n",
    "- interestingly, the learning rates differed substantially - XGB used 0.08, while LGBM used 0.29.\n",
    "- both models have used tree based boosting - this means that the trees were built sequentially, with each tree trying to correct the mistakes of the previous tree. This is a good approach for imbalanced data, as the trees will try to correct the mistakes of the previous trees, which will lead to better predictions for the minority class. Though, the XGB used gbtree (default), while in LGBM we have used dart. The dart stands for \"dropouts meet multiple additive regression trees\". It incorporates dropout into the tree building process, which is a regularization technique. This means that some of the trees will be dropped (ignored) during each boosting round, which will lead to better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "429685d20490a14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T19:50:51.929792Z",
     "start_time": "2023-12-09T19:50:49.260688Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(2, 2, figsize=(20, 10))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    pd.Series(results.results[i].best_model['model'].feature_importances_, index=X_train_numeric.columns).groupby(lambda x: x.split('_')[0]).mean().sort_values(ascending=False).plot(kind='barh')\n",
    "    plt.title(results.results[i].get_model_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31847e2524fae434",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In all of the models, the most important features were:\n",
    "- feat10\n",
    "- duration\n",
    "- checking_status\n",
    "- feat01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234cc2d7-7cab-4e18-8f04-9d4311d413a8",
   "metadata": {},
   "source": [
    "### Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbff6c2-ffec-482a-a9e3-30feee1ab5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.21\" 2023-10-17; OpenJDK Runtime Environment (build 11.0.21+9-post-Ubuntu-0ubuntu122.04); OpenJDK 64-Bit Server VM (build 11.0.21+9-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
      "  Starting server from /home/ubuntu/.local/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpxfdx2v4c\n",
      "  JVM stdout: /tmp/tmpxfdx2v4c/h2o_ubuntu_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpxfdx2v4c/h2o_ubuntu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 4 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ubuntu_uume5t</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>29.97 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>30</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>30</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    1 month and 4 days\n",
       "H2O_cluster_name:           H2O_from_python_ubuntu_uume5t\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    29.97 Gb\n",
       "H2O_cluster_total_cores:    30\n",
       "H2O_cluster_allowed_cores:  30\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "df['class'] = df['class'].map({'good': 0, 'bad': 1})\n",
    "dfh = h2o.H2OFrame(df.drop(columns=['purpose', 'personal_status', 'own_telephone', 'other_parties']))\n",
    "train, test = dfh.split_frame([0.8])\n",
    "train['class'] = train['class'].asfactor()\n",
    "test['class'] = test['class'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715799c2-5ba6-494a-87df-f2bd231a08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "aml_atp = h2o.automl.H2OAutoML(max_runtime_secs=600, stopping_metric='aucpr', nfolds=5, sort_metric='aucpr')\n",
    "aml_atp.train(x=[col for col in train.columns if col != 'class'], y='class', training_frame=train)\n",
    "lb = aml_atp.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f9a822-e36e-4442-a8d6-ed20449a95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "def oos_predict_with_h2o(model_id, test_frame):\n",
    "    return average_precision_score(test_frame.as_data_frame()['class'],h2o.get_model(model_id).predict(test_frame).as_data_frame()['p1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be3132e-3b0d-4aa8-91f7-01e0c0692d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/h2o/frame.py:1979: H2ODependencyWarning: converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above).\n",
      "  warnings.warn(\"converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>aucpr</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>oos_aucpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsemble_AllModels_3_AutoML_1_20240124_...</td>\n",
       "      <td>0.844051</td>\n",
       "      <td>0.918391</td>\n",
       "      <td>0.328973</td>\n",
       "      <td>0.152699</td>\n",
       "      <td>0.318435</td>\n",
       "      <td>0.101401</td>\n",
       "      <td>0.878440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsemble_AllModels_6_AutoML_1_20240124_...</td>\n",
       "      <td>0.842275</td>\n",
       "      <td>0.917462</td>\n",
       "      <td>0.331707</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.320562</td>\n",
       "      <td>0.102760</td>\n",
       "      <td>0.876521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StackedEnsemble_AllModels_5_AutoML_1_20240124_...</td>\n",
       "      <td>0.808053</td>\n",
       "      <td>0.903754</td>\n",
       "      <td>0.361078</td>\n",
       "      <td>0.177801</td>\n",
       "      <td>0.331241</td>\n",
       "      <td>0.109721</td>\n",
       "      <td>0.867040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_6_AutoML_1_202401...</td>\n",
       "      <td>0.830199</td>\n",
       "      <td>0.910744</td>\n",
       "      <td>0.343080</td>\n",
       "      <td>0.157489</td>\n",
       "      <td>0.325949</td>\n",
       "      <td>0.106243</td>\n",
       "      <td>0.866203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_4_AutoML_1_202401...</td>\n",
       "      <td>0.831014</td>\n",
       "      <td>0.910608</td>\n",
       "      <td>0.343370</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.326054</td>\n",
       "      <td>0.106312</td>\n",
       "      <td>0.861012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_1_20240124_220002_m...</td>\n",
       "      <td>0.691446</td>\n",
       "      <td>0.835041</td>\n",
       "      <td>0.515263</td>\n",
       "      <td>0.241359</td>\n",
       "      <td>0.397525</td>\n",
       "      <td>0.158026</td>\n",
       "      <td>0.679373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>XGBoost_grid_1_AutoML_1_20240124_220002_model_22</td>\n",
       "      <td>0.691020</td>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.462051</td>\n",
       "      <td>0.249242</td>\n",
       "      <td>0.387372</td>\n",
       "      <td>0.150057</td>\n",
       "      <td>0.677065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_1_20240124_220002_m...</td>\n",
       "      <td>0.739122</td>\n",
       "      <td>0.860452</td>\n",
       "      <td>0.525839</td>\n",
       "      <td>0.222630</td>\n",
       "      <td>0.375850</td>\n",
       "      <td>0.141263</td>\n",
       "      <td>0.666643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>DeepLearning_grid_1_AutoML_1_20240124_220002_m...</td>\n",
       "      <td>0.631214</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>2.531045</td>\n",
       "      <td>0.246847</td>\n",
       "      <td>0.448385</td>\n",
       "      <td>0.201049</td>\n",
       "      <td>0.665899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>DeepLearning_grid_2_AutoML_1_20240124_220002_m...</td>\n",
       "      <td>0.679949</td>\n",
       "      <td>0.824846</td>\n",
       "      <td>0.461197</td>\n",
       "      <td>0.254033</td>\n",
       "      <td>0.389460</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.644686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model_id     aucpr       auc  \\\n",
       "0    StackedEnsemble_AllModels_3_AutoML_1_20240124_...  0.844051  0.918391   \n",
       "1    StackedEnsemble_AllModels_6_AutoML_1_20240124_...  0.842275  0.917462   \n",
       "6    StackedEnsemble_AllModels_5_AutoML_1_20240124_...  0.808053  0.903754   \n",
       "3    StackedEnsemble_BestOfFamily_6_AutoML_1_202401...  0.830199  0.910744   \n",
       "2    StackedEnsemble_BestOfFamily_4_AutoML_1_202401...  0.831014  0.910608   \n",
       "..                                                 ...       ...       ...   \n",
       "114  DeepLearning_grid_1_AutoML_1_20240124_220002_m...  0.691446  0.835041   \n",
       "115   XGBoost_grid_1_AutoML_1_20240124_220002_model_22  0.691020  0.835676   \n",
       "71   DeepLearning_grid_1_AutoML_1_20240124_220002_m...  0.739122  0.860452   \n",
       "126  DeepLearning_grid_1_AutoML_1_20240124_220002_m...  0.631214  0.801136   \n",
       "119  DeepLearning_grid_2_AutoML_1_20240124_220002_m...  0.679949  0.824846   \n",
       "\n",
       "      logloss  mean_per_class_error      rmse       mse  oos_aucpr  \n",
       "0    0.328973              0.152699  0.318435  0.101401   0.878440  \n",
       "1    0.331707              0.154354  0.320562  0.102760   0.876521  \n",
       "6    0.361078              0.177801  0.331241  0.109721   0.867040  \n",
       "3    0.343080              0.157489  0.325949  0.106243   0.866203  \n",
       "2    0.343370              0.161685  0.326054  0.106312   0.861012  \n",
       "..        ...                   ...       ...       ...        ...  \n",
       "114  0.515263              0.241359  0.397525  0.158026   0.679373  \n",
       "115  0.462051              0.249242  0.387372  0.150057   0.677065  \n",
       "71   0.525839              0.222630  0.375850  0.141263   0.666643  \n",
       "126  2.531045              0.246847  0.448385  0.201049   0.665899  \n",
       "119  0.461197              0.254033  0.389460  0.151679   0.644686  \n",
       "\n",
       "[127 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = lb.as_data_frame()\n",
    "leaderboard['oos_aucpr'] = leaderboard['model_id'].apply(lambda x: oos_predict_with_h2o(x, test))\n",
    "leaderboard.sort_values(by='oos_aucpr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0bd84b2-e061-44b4-8830-a87455ffee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_6_AutoML_5_20240124_212301\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>3/6</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># XGBoost base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>0/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>Random</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.001051861753359648\n",
       "RMSE: 0.032432418247174355\n",
       "LogLoss: 0.023870381710730568\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "Null degrees of freedom: 1599\n",
       "Residual degrees of freedom: 1596\n",
       "Null deviance: 1977.909952581559\n",
       "Residual deviance: 76.3852214743378\n",
       "AIC: 84.3852214743378</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8850907691026312</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>1106.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1106.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>494.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/494.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1106.0</td>\n",
       "<td>494.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1600.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9994913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9994913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9994913</td>\n",
       "<td>1106.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9994913</td>\n",
       "<td>493.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0005283</td>\n",
       "<td>1106.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.8850908</td>\n",
       "<td>494.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9994913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9994913</td>\n",
       "<td>0.9979757</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0005283</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.8850908</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 30.88 %, avg score: 32.01 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.9973094</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980986</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.0323887</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.0323887</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9962035</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968502</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974744</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.0647773</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.0647773</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.9952797</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956739</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968742</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.0971660</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.0971660</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9943251</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9947862</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963522</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.1295547</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.1295547</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9936606</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940868</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9958991</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.1619433</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.1619433</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9894704</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917748</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938369</td>\n",
       "<td>0.1619433</td>\n",
       "<td>0.3238866</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.3238866</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.9849666</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872911</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9916550</td>\n",
       "<td>0.1619433</td>\n",
       "<td>0.4858300</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.4858300</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.9793449</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9825638</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9893822</td>\n",
       "<td>0.1619433</td>\n",
       "<td>0.6477733</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.6477733</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.9444969</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9677094</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9821579</td>\n",
       "<td>0.3238866</td>\n",
       "<td>0.9716599</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.9716599</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0499387</td>\n",
       "<td>0.2834008</td>\n",
       "<td>2.5000000</td>\n",
       "<td>0.0875</td>\n",
       "<td>0.1493254</td>\n",
       "<td>0.771875</td>\n",
       "<td>0.7739498</td>\n",
       "<td>0.0283401</td>\n",
       "<td>1.0</td>\n",
       "<td>-71.6599190</td>\n",
       "<td>150.0000000</td>\n",
       "<td>0.8679928</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0310697</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0397907</td>\n",
       "<td>0.6175</td>\n",
       "<td>0.6271180</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.7233273</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0224961</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0266324</td>\n",
       "<td>0.5145833</td>\n",
       "<td>0.5270371</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td>\n",
       "<td>0.5786618</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0150177</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0185880</td>\n",
       "<td>0.4410714</td>\n",
       "<td>0.4544015</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td>\n",
       "<td>0.4339964</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0091259</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2500000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0119185</td>\n",
       "<td>0.3859375</td>\n",
       "<td>0.3990911</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0000000</td>\n",
       "<td>0.2893309</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0042341</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0065962</td>\n",
       "<td>0.3430556</td>\n",
       "<td>0.3554806</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td>\n",
       "<td>0.1446655</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004231</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021302</td>\n",
       "<td>0.30875</td>\n",
       "<td>0.3201455</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10598047814269983\n",
       "RMSE: 0.3255464300874759\n",
       "LogLoss: 0.34516795219302865\n",
       "AUC: 0.9090231054754706\n",
       "AUCPR: 0.8305368262826908\n",
       "Gini: 0.8180462109509412\n",
       "Null degrees of freedom: 1599\n",
       "Residual degrees of freedom: 1596\n",
       "Null deviance: 1979.8128870859296\n",
       "Residual deviance: 1104.5374470176916\n",
       "AIC: 1112.5374470176916</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39512074440858014</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>983.0</td>\n",
       "<td>123.0</td>\n",
       "<td>0.1112</td>\n",
       "<td> (123.0/1106.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>104.0</td>\n",
       "<td>390.0</td>\n",
       "<td>0.2105</td>\n",
       "<td> (104.0/494.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1087.0</td>\n",
       "<td>513.0</td>\n",
       "<td>0.1419</td>\n",
       "<td> (227.0/1600.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3951207</td>\n",
       "<td>0.7745780</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2358657</td>\n",
       "<td>0.8241966</td>\n",
       "<td>255.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6508206</td>\n",
       "<td>0.7904609</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3981107</td>\n",
       "<td>0.858125</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9994171</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0067071</td>\n",
       "<td>1.0</td>\n",
       "<td>391.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9994171</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3951207</td>\n",
       "<td>0.6713750</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3081084</td>\n",
       "<td>0.8435805</td>\n",
       "<td>229.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3019015</td>\n",
       "<td>0.8451911</td>\n",
       "<td>232.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9994171</td>\n",
       "<td>1106.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9994171</td>\n",
       "<td>493.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0008265</td>\n",
       "<td>1106.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0067071</td>\n",
       "<td>494.0</td>\n",
       "<td>391.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9994171</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9994171</td>\n",
       "<td>0.9979757</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0008265</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0067071</td>\n",
       "<td>1.0</td>\n",
       "<td>391.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 30.88 %, avg score: 30.89 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.9874919</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935235</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935235</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.0323887</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.0323887</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.9778136</td>\n",
       "<td>3.2388664</td>\n",
       "<td>3.2388664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9819650</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9877442</td>\n",
       "<td>0.0323887</td>\n",
       "<td>0.0647773</td>\n",
       "<td>223.8866397</td>\n",
       "<td>223.8866397</td>\n",
       "<td>0.0647773</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.9686459</td>\n",
       "<td>2.8340081</td>\n",
       "<td>3.1039136</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9732982</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9829289</td>\n",
       "<td>0.0283401</td>\n",
       "<td>0.0931174</td>\n",
       "<td>183.4008097</td>\n",
       "<td>210.3913630</td>\n",
       "<td>0.0913091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.9603986</td>\n",
       "<td>2.6315789</td>\n",
       "<td>2.9858300</td>\n",
       "<td>0.8125</td>\n",
       "<td>0.9652231</td>\n",
       "<td>0.921875</td>\n",
       "<td>0.9785025</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.1194332</td>\n",
       "<td>163.1578947</td>\n",
       "<td>198.5829960</td>\n",
       "<td>0.1149124</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9468833</td>\n",
       "<td>3.0364372</td>\n",
       "<td>2.9959514</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9532601</td>\n",
       "<td>0.925</td>\n",
       "<td>0.9734540</td>\n",
       "<td>0.0303644</td>\n",
       "<td>0.1497976</td>\n",
       "<td>203.6437247</td>\n",
       "<td>199.5951417</td>\n",
       "<td>0.1443726</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.8756579</td>\n",
       "<td>3.0769231</td>\n",
       "<td>3.0364372</td>\n",
       "<td>0.95</td>\n",
       "<td>0.9135325</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9434933</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.3036437</td>\n",
       "<td>207.6923077</td>\n",
       "<td>203.6437247</td>\n",
       "<td>0.2946021</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.7717455</td>\n",
       "<td>2.7125506</td>\n",
       "<td>2.9284750</td>\n",
       "<td>0.8375</td>\n",
       "<td>0.8283430</td>\n",
       "<td>0.9041667</td>\n",
       "<td>0.9051098</td>\n",
       "<td>0.1356275</td>\n",
       "<td>0.4392713</td>\n",
       "<td>171.2550607</td>\n",
       "<td>192.8475034</td>\n",
       "<td>0.4184756</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6863210</td>\n",
       "<td>2.4696356</td>\n",
       "<td>2.8137652</td>\n",
       "<td>0.7625</td>\n",
       "<td>0.7309430</td>\n",
       "<td>0.86875</td>\n",
       "<td>0.8615681</td>\n",
       "<td>0.1234818</td>\n",
       "<td>0.5627530</td>\n",
       "<td>146.9635628</td>\n",
       "<td>181.3765182</td>\n",
       "<td>0.5247784</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.4419831</td>\n",
       "<td>1.8623482</td>\n",
       "<td>2.4966262</td>\n",
       "<td>0.575</td>\n",
       "<td>0.5575488</td>\n",
       "<td>0.7708333</td>\n",
       "<td>0.7602283</td>\n",
       "<td>0.1862348</td>\n",
       "<td>0.7489879</td>\n",
       "<td>86.2348178</td>\n",
       "<td>149.6626181</td>\n",
       "<td>0.6495303</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2606659</td>\n",
       "<td>1.2145749</td>\n",
       "<td>2.1761134</td>\n",
       "<td>0.375</td>\n",
       "<td>0.3434053</td>\n",
       "<td>0.671875</td>\n",
       "<td>0.6560226</td>\n",
       "<td>0.1214575</td>\n",
       "<td>0.8704453</td>\n",
       "<td>21.4574899</td>\n",
       "<td>117.6113360</td>\n",
       "<td>0.6805719</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1579656</td>\n",
       "<td>0.3643725</td>\n",
       "<td>1.8137652</td>\n",
       "<td>0.1125</td>\n",
       "<td>0.2026941</td>\n",
       "<td>0.56</td>\n",
       "<td>0.5653569</td>\n",
       "<td>0.0364372</td>\n",
       "<td>0.9068826</td>\n",
       "<td>-63.5627530</td>\n",
       "<td>81.3765182</td>\n",
       "<td>0.5886186</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0977127</td>\n",
       "<td>0.3643725</td>\n",
       "<td>1.5721997</td>\n",
       "<td>0.1125</td>\n",
       "<td>0.1245219</td>\n",
       "<td>0.4854167</td>\n",
       "<td>0.4918844</td>\n",
       "<td>0.0364372</td>\n",
       "<td>0.9433198</td>\n",
       "<td>-63.5627530</td>\n",
       "<td>57.2199730</td>\n",
       "<td>0.4966652</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0570922</td>\n",
       "<td>0.3643725</td>\n",
       "<td>1.3996530</td>\n",
       "<td>0.1125</td>\n",
       "<td>0.0759912</td>\n",
       "<td>0.4321429</td>\n",
       "<td>0.4324711</td>\n",
       "<td>0.0364372</td>\n",
       "<td>0.9797571</td>\n",
       "<td>-63.5627530</td>\n",
       "<td>39.9652979</td>\n",
       "<td>0.4047119</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0264605</td>\n",
       "<td>0.1214575</td>\n",
       "<td>1.2398785</td>\n",
       "<td>0.0375</td>\n",
       "<td>0.0397619</td>\n",
       "<td>0.3828125</td>\n",
       "<td>0.3833824</td>\n",
       "<td>0.0121457</td>\n",
       "<td>0.9919028</td>\n",
       "<td>-87.8542510</td>\n",
       "<td>23.9878543</td>\n",
       "<td>0.2776171</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0098483</td>\n",
       "<td>0.0404858</td>\n",
       "<td>1.1066127</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.0178016</td>\n",
       "<td>0.3416667</td>\n",
       "<td>0.3427623</td>\n",
       "<td>0.0040486</td>\n",
       "<td>0.9959514</td>\n",
       "<td>-95.9514170</td>\n",
       "<td>10.6612686</td>\n",
       "<td>0.1388086</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004839</td>\n",
       "<td>0.0404858</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0125</td>\n",
       "<td>0.0045457</td>\n",
       "<td>0.30875</td>\n",
       "<td>0.3089407</td>\n",
       "<td>0.0040486</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.9514170</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8593438</td>\n",
       "<td>0.0063635</td>\n",
       "<td>0.8610272</td>\n",
       "<td>0.8547297</td>\n",
       "<td>0.852071</td>\n",
       "<td>0.8603896</td>\n",
       "<td>0.8685015</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9095142</td>\n",
       "<td>0.0114848</td>\n",
       "<td>0.8909014</td>\n",
       "<td>0.9117857</td>\n",
       "<td>0.9128131</td>\n",
       "<td>0.9097078</td>\n",
       "<td>0.9223629</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1406562</td>\n",
       "<td>0.0063635</td>\n",
       "<td>0.1389728</td>\n",
       "<td>0.1452703</td>\n",
       "<td>0.147929</td>\n",
       "<td>0.1396104</td>\n",
       "<td>0.1314985</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>45.0</td>\n",
       "<td>3.082207</td>\n",
       "<td>46.0</td>\n",
       "<td>43.0</td>\n",
       "<td>50.0</td>\n",
       "<td>43.0</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7617627</td>\n",
       "<td>0.0194588</td>\n",
       "<td>0.7905138</td>\n",
       "<td>0.7720588</td>\n",
       "<td>0.7433490</td>\n",
       "<td>0.7475728</td>\n",
       "<td>0.7553192</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7827736</td>\n",
       "<td>0.0114979</td>\n",
       "<td>0.776699</td>\n",
       "<td>0.7962086</td>\n",
       "<td>0.7916667</td>\n",
       "<td>0.7817259</td>\n",
       "<td>0.7675676</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.8062695</td>\n",
       "<td>0.0337842</td>\n",
       "<td>0.7633588</td>\n",
       "<td>0.8219178</td>\n",
       "<td>0.8467023</td>\n",
       "<td>0.8191490</td>\n",
       "<td>0.7802198</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.2518938</td>\n",
       "<td>0.2615679</td>\n",
       "<td>3.1226416</td>\n",
       "<td>2.96</td>\n",
       "<td>3.1588786</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.6333334</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.3452103</td>\n",
       "<td>0.0275033</td>\n",
       "<td>0.3819622</td>\n",
       "<td>0.3568322</td>\n",
       "<td>0.3379435</td>\n",
       "<td>0.3425768</td>\n",
       "<td>0.3067367</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.1869485</td>\n",
       "<td>0.0397259</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.16</td>\n",
       "<td>0.1645022</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.2111111</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1508442</td>\n",
       "<td>0.0112178</td>\n",
       "<td>0.1670860</td>\n",
       "<td>0.1488775</td>\n",
       "<td>0.1383259</td>\n",
       "<td>0.1437433</td>\n",
       "<td>0.1561885</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1061448</td>\n",
       "<td>0.0077791</td>\n",
       "<td>0.1152078</td>\n",
       "<td>0.1110337</td>\n",
       "<td>0.1029274</td>\n",
       "<td>0.1066108</td>\n",
       "<td>0.0949443</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>395.9626</td>\n",
       "<td>21.49526</td>\n",
       "<td>415.43265</td>\n",
       "<td>380.38904</td>\n",
       "<td>422.15195</td>\n",
       "<td>374.2825</td>\n",
       "<td>387.55673</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.831692</td>\n",
       "<td>0.0203107</td>\n",
       "<td>0.8070177</td>\n",
       "<td>0.8339737</td>\n",
       "<td>0.8510538</td>\n",
       "<td>0.8150884</td>\n",
       "<td>0.8513264</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.7489652</td>\n",
       "<td>0.0330869</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7567568</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.7264151</td>\n",
       "<td>0.7473684</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5021126</td>\n",
       "<td>0.0232374</td>\n",
       "<td>0.4707636</td>\n",
       "<td>0.5036567</td>\n",
       "<td>0.5242611</td>\n",
       "<td>0.4878450</td>\n",
       "<td>0.5240364</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8235220</td>\n",
       "<td>0.0520948</td>\n",
       "<td>0.754717</td>\n",
       "<td>0.84</td>\n",
       "<td>0.8878505</td>\n",
       "<td>0.8461539</td>\n",
       "<td>0.7888889</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>220.83733</td>\n",
       "<td>20.499428</td>\n",
       "<td>252.859</td>\n",
       "<td>211.24464</td>\n",
       "<td>228.44981</td>\n",
       "<td>211.02731</td>\n",
       "<td>200.60583</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3256213</td>\n",
       "<td>0.0120201</td>\n",
       "<td>0.3394228</td>\n",
       "<td>0.3332172</td>\n",
       "<td>0.320823</td>\n",
       "<td>0.3265131</td>\n",
       "<td>0.3081304</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8747895</td>\n",
       "<td>0.0302691</td>\n",
       "<td>0.9111111</td>\n",
       "<td>0.8622449</td>\n",
       "<td>0.8354979</td>\n",
       "<td>0.8663595</td>\n",
       "<td>0.8987342</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_6_AutoML_5_20240124_212301\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       3/6\n",
       "# GBM base models (used / total)           1/1\n",
       "# XGBoost base models (used / total)       1/1\n",
       "# DeepLearning base models (used / total)  1/1\n",
       "# DRF base models (used / total)           0/2\n",
       "# GLM base models (used / total)           0/1\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         Random\n",
       "Metalearner nfolds                         5\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.001051861753359648\n",
       "RMSE: 0.032432418247174355\n",
       "LogLoss: 0.023870381710730568\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "Null degrees of freedom: 1599\n",
       "Residual degrees of freedom: 1596\n",
       "Null deviance: 1977.909952581559\n",
       "Residual deviance: 76.3852214743378\n",
       "AIC: 84.3852214743378\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8850907691026312\n",
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  ------------\n",
       "0      1106  0    0        (0.0/1106.0)\n",
       "1      0     494  0        (0.0/494.0)\n",
       "Total  1106  494  0        (0.0/1600.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.885091     1         142\n",
       "max f2                       0.885091     1         142\n",
       "max f0point5                 0.885091     1         142\n",
       "max accuracy                 0.885091     1         142\n",
       "max precision                0.999491     1         0\n",
       "max recall                   0.885091     1         142\n",
       "max specificity              0.999491     1         0\n",
       "max absolute_mcc             0.885091     1         142\n",
       "max min_per_class_accuracy   0.885091     1         142\n",
       "max mean_per_class_accuracy  0.885091     1         142\n",
       "max tns                      0.999491     1106      0\n",
       "max fns                      0.999491     493       0\n",
       "max fps                      0.000528254  1106      399\n",
       "max tps                      0.885091     494       142\n",
       "max tnr                      0.999491     1         0\n",
       "max fnr                      0.999491     0.997976  0\n",
       "max fpr                      0.000528254  1         399\n",
       "max tpr                      0.885091     1         142\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 30.88 %, avg score: 32.01 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.997309           3.23887   3.23887            1                0.998099    1                           0.998099            0.0323887       0.0323887                  223.887   223.887            0.0323887\n",
       "2        0.02                        0.996204           3.23887   3.23887            1                0.99685     1                           0.997474            0.0323887       0.0647773                  223.887   223.887            0.0647773\n",
       "3        0.03                        0.99528            3.23887   3.23887            1                0.995674    1                           0.996874            0.0323887       0.097166                   223.887   223.887            0.097166\n",
       "4        0.04                        0.994325           3.23887   3.23887            1                0.994786    1                           0.996352            0.0323887       0.129555                   223.887   223.887            0.129555\n",
       "5        0.05                        0.993661           3.23887   3.23887            1                0.994087    1                           0.995899            0.0323887       0.161943                   223.887   223.887            0.161943\n",
       "6        0.1                         0.98947            3.23887   3.23887            1                0.991775    1                           0.993837            0.161943        0.323887                   223.887   223.887            0.323887\n",
       "7        0.15                        0.984967           3.23887   3.23887            1                0.987291    1                           0.991655            0.161943        0.48583                    223.887   223.887            0.48583\n",
       "8        0.2                         0.979345           3.23887   3.23887            1                0.982564    1                           0.989382            0.161943        0.647773                   223.887   223.887            0.647773\n",
       "9        0.3                         0.944497           3.23887   3.23887            1                0.967709    1                           0.982158            0.323887        0.97166                    223.887   223.887            0.97166\n",
       "10       0.4                         0.0499387          0.283401  2.5                0.0875           0.149325    0.771875                    0.77395             0.0283401       1                          -71.6599  150                0.867993\n",
       "11       0.5                         0.0310697          0         2                  0                0.0397907   0.6175                      0.627118            0               1                          -100      100                0.723327\n",
       "12       0.6                         0.0224961          0         1.66667            0                0.0266324   0.514583                    0.527037            0               1                          -100      66.6667            0.578662\n",
       "13       0.7                         0.0150177          0         1.42857            0                0.018588    0.441071                    0.454401            0               1                          -100      42.8571            0.433996\n",
       "14       0.8                         0.00912589         0         1.25               0                0.0119185   0.385937                    0.399091            0               1                          -100      25                 0.289331\n",
       "15       0.9                         0.00423408         0         1.11111            0                0.00659625  0.343056                    0.355481            0               1                          -100      11.1111            0.144665\n",
       "16       1                           0.000423058        0         1                  0                0.00213025  0.30875                     0.320146            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10598047814269983\n",
       "RMSE: 0.3255464300874759\n",
       "LogLoss: 0.34516795219302865\n",
       "AUC: 0.9090231054754706\n",
       "AUCPR: 0.8305368262826908\n",
       "Gini: 0.8180462109509412\n",
       "Null degrees of freedom: 1599\n",
       "Residual degrees of freedom: 1596\n",
       "Null deviance: 1979.8128870859296\n",
       "Residual deviance: 1104.5374470176916\n",
       "AIC: 1112.5374470176916\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39512074440858014\n",
       "       0     1    Error    Rate\n",
       "-----  ----  ---  -------  --------------\n",
       "0      983   123  0.1112   (123.0/1106.0)\n",
       "1      104   390  0.2105   (104.0/494.0)\n",
       "Total  1087  513  0.1419   (227.0/1600.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.395121     0.774578  199\n",
       "max f2                       0.235866     0.824197  255\n",
       "max f0point5                 0.650821     0.790461  123\n",
       "max accuracy                 0.398111     0.858125  198\n",
       "max precision                0.999417     1         0\n",
       "max recall                   0.00670714   1         391\n",
       "max specificity              0.999417     1         0\n",
       "max absolute_mcc             0.395121     0.671375  199\n",
       "max min_per_class_accuracy   0.308108     0.84358   229\n",
       "max mean_per_class_accuracy  0.301902     0.845191  232\n",
       "max tns                      0.999417     1106      0\n",
       "max fns                      0.999417     493       0\n",
       "max fps                      0.000826476  1106      399\n",
       "max tps                      0.00670714   494       391\n",
       "max tnr                      0.999417     1         0\n",
       "max fnr                      0.999417     0.997976  0\n",
       "max fpr                      0.000826476  1         399\n",
       "max tpr                      0.00670714   1         391\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 30.88 %, avg score: 30.89 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.987492           3.23887    3.23887            1                0.993523    1                           0.993523            0.0323887       0.0323887                  223.887   223.887            0.0323887\n",
       "2        0.02                        0.977814           3.23887    3.23887            1                0.981965    1                           0.987744            0.0323887       0.0647773                  223.887   223.887            0.0647773\n",
       "3        0.03                        0.968646           2.83401    3.10391            0.875            0.973298    0.958333                    0.982929            0.0283401       0.0931174                  183.401   210.391            0.0913091\n",
       "4        0.04                        0.960399           2.63158    2.98583            0.8125           0.965223    0.921875                    0.978502            0.0263158       0.119433                   163.158   198.583            0.114912\n",
       "5        0.05                        0.946883           3.03644    2.99595            0.9375           0.95326     0.925                       0.973454            0.0303644       0.149798                   203.644   199.595            0.144373\n",
       "6        0.1                         0.875658           3.07692    3.03644            0.95             0.913533    0.9375                      0.943493            0.153846        0.303644                   207.692   203.644            0.294602\n",
       "7        0.15                        0.771746           2.71255    2.92848            0.8375           0.828343    0.904167                    0.90511             0.135628        0.439271                   171.255   192.848            0.418476\n",
       "8        0.2                         0.686321           2.46964    2.81377            0.7625           0.730943    0.86875                     0.861568            0.123482        0.562753                   146.964   181.377            0.524778\n",
       "9        0.3                         0.441983           1.86235    2.49663            0.575            0.557549    0.770833                    0.760228            0.186235        0.748988                   86.2348   149.663            0.64953\n",
       "10       0.4                         0.260666           1.21457    2.17611            0.375            0.343405    0.671875                    0.656023            0.121457        0.870445                   21.4575   117.611            0.680572\n",
       "11       0.5                         0.157966           0.364372   1.81377            0.1125           0.202694    0.56                        0.565357            0.0364372       0.906883                   -63.5628  81.3765            0.588619\n",
       "12       0.6                         0.0977127          0.364372   1.5722             0.1125           0.124522    0.485417                    0.491884            0.0364372       0.94332                    -63.5628  57.22              0.496665\n",
       "13       0.7                         0.0570922          0.364372   1.39965            0.1125           0.0759912   0.432143                    0.432471            0.0364372       0.979757                   -63.5628  39.9653            0.404712\n",
       "14       0.8                         0.0264605          0.121457   1.23988            0.0375           0.0397619   0.382812                    0.383382            0.0121457       0.991903                   -87.8543  23.9879            0.277617\n",
       "15       0.9                         0.00984828         0.0404858  1.10661            0.0125           0.0178016   0.341667                    0.342762            0.00404858      0.995951                   -95.9514  10.6613            0.138809\n",
       "16       1                           0.00048389         0.0404858  1                  0.0125           0.00454565  0.30875                     0.308941            0.00404858      1                          -95.9514  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                      mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "--------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy              0.8593438    0.006363464   0.8610272     0.8547297     0.852071      0.8603896     0.86850154\n",
       "auc                   0.9095142    0.0114847915  0.89090145    0.9117857     0.91281307    0.9097078     0.92236286\n",
       "err                   0.14065619   0.006363464   0.1389728     0.14527027    0.147929      0.1396104     0.13149847\n",
       "err_count             45.0         3.082207      46.0          43.0          50.0          43.0          43.0\n",
       "f0point5              0.76176274   0.01945877    0.7905138     0.77205884    0.74334896    0.74757284    0.7553192\n",
       "f1                    0.78277355   0.011497886   0.776699      0.79620856    0.7916667     0.7817259     0.7675676\n",
       "f2                    0.8062695    0.03378417    0.7633588     0.82191783    0.84670234    0.81914896    0.7802198\n",
       "lift_top_group        3.2518938    0.26156792    3.1226416     2.96          3.1588786     3.3846154     3.6333334\n",
       "logloss               0.34521028   0.027503306   0.3819622     0.35683218    0.33794352    0.3425768     0.30673674\n",
       "max_per_class_error   0.1869485    0.03972585    0.24528302    0.16          0.16450216    0.15384616    0.21111111\n",
       "---                   ---          ---           ---           ---           ---           ---           ---\n",
       "mean_per_class_error  0.15084423   0.011217783   0.16708596    0.14887755    0.13832586    0.14374335    0.15618847\n",
       "mse                   0.106144816  0.0077791237  0.11520784    0.1110337     0.10292741    0.10661078    0.09494434\n",
       "null_deviance         395.9626     21.49526      415.43265     380.38904     422.15195     374.2825      387.55673\n",
       "pr_auc                0.831692     0.02031067    0.8070177     0.8339737     0.8510538     0.81508845    0.8513264\n",
       "precision             0.7489652    0.03308694    0.8           0.7567568     0.71428573    0.7264151     0.7473684\n",
       "r2                    0.50211257   0.02323743    0.47076365    0.5036567     0.52426106    0.48784497    0.5240364\n",
       "recall                0.82352203   0.05209477    0.754717      0.84          0.88785046    0.84615386    0.7888889\n",
       "residual_deviance     220.83733    20.499428     252.859       211.24464     228.44981     211.02731     200.60583\n",
       "rmse                  0.3256213    0.012020083   0.33942282    0.3332172     0.320823      0.32651305    0.3081304\n",
       "specificity           0.8747895    0.030269105   0.9111111     0.8622449     0.83549786    0.8663595     0.89873415\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.get_model(leaderboard.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29813f-0897-4082-a656-47b6d0ed38a9",
   "metadata": {},
   "source": [
    "In this section, we have tried out ensemble methods for prediction. We utilized H2O AutoML for the ensemble models building.\n",
    "The best model, a stacked ensemble of multiple types of models, utilizes a cross-validation stacking strategy with models including 5 GBMs, 2 XGBoost, and 5 DeepLearning models. The metalearner was implemented with GLM. We can notice the model was overfit on the training data, though the Cross-Validation performance of the stacked ensemble model is still good, greater than single boosting model we have created, achieving PR AUC of 0.842 with a standard deviation of 0.024. This indicates that the model consistently performs well across different folds, showcasing stability and reliability/somewhat generalization. When it comes to OOS test, model achieved even higher AUCPR of 0.878 - about 0.08 pp above the LGBM we have mentioned earlier. In this particular task, we have managed to increase our predictions quality with stacking the models - although, we have sacrificed model explanability this way. This is a double-edged sword that should be used with caution. For this particular case, that involves credit risk, due to financial regulations, explainable models are currently the only ones available to the markets as far as I am concerned. This is in line with responsible AI usage - credit risk should be measured in a way that does not involve discrimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0f92f60e086d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary\n",
    "In this comprehensive project on the German Credit Risk dataset, we conducted a thorough analysis encompassing Exploratory Data Analysis (EDA), variable transformations, selection, model training, and evaluation. Employing a diverse set of models, including RandomForest, XGBoost (XGB), ExtraTrees, and LightGBM (LGBM), we fine-tuned hyperparameters through RandomizedSearchCV. To mitigate overfitting, we implemented StratifiedKFold cross-validation. Our metric of choice was average precision score, due to it's ability to perform well in imbalanced problems.\n",
    "\n",
    "#### Model Performance\n",
    "In assessing out-of-sample data, the boosting methods—XGB and LGBM—demonstrated superior performance compared to RandomForest and ExtraTrees. This observation underscores the effectiveness of gradient boosting algorithms in capturing complex patterns within the dataset.\n",
    "\n",
    "#### Advanced Approach: AutoML with H2O Stacked Ensemble\n",
    "Venturing into advanced methodologies, we explored the application of AutoML through H2O for constructing stacked ensembles. Notably, these models surpassed the performance of our previous methods. However, it is crucial to note that this improvement comes at the expense of model explainability. Users should exercise caution and consider the trade-off between enhanced performance and interpretability when opting for stacked ensemble models generated through AutoML in H2O.\n",
    "\n",
    "#### Key Takeaway\n",
    "This project provides insights into credit risk modeling and sheds light on the trade-offs when using advanced techniques like stacked ensembles. It emphasizes the importance of balancing performance gains with interpretability in real-world applications.\n",
    "\n",
    "#### Further Steps\n",
    "When applying those kinds of model in real world, we would like to suggest using XAI libraries, such as DALEX, for interpreting model's results. This can be crucial in business understanding of the decisions made and is a great addition for model's performance evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
